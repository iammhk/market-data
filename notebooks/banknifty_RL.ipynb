{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622d17c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ LOADING BANK NIFTY OPTIONS DATA\n",
      "==================================================\n",
      "üìÇ Project root: c:\\Users\\91894\\Projects\\market-data\n",
      "üîß Source path: c:\\Users\\91894\\Projects\\market-data\\src\n",
      "‚úÖ Successfully imported options_data_loader\n",
      "üìÅ Data path: c:\\Users\\91894\\Projects\\market-data\\data\n",
      "\n",
      "üîÑ Loading Bank Nifty options data...\n",
      "üìÇ LOADING BANK NIFTY OPTIONS DATA\n",
      "========================================\n",
      "üìã Found 22 Bank Nifty options files:\n",
      "  1. OPTIDX_BANKNIFTY_CE_01-Apr-2023_TO_30-Jun-2023.csv\n",
      "  2. OPTIDX_BANKNIFTY_CE_01-Apr-2024_TO_30-Jun-2024.csv\n",
      "  3. OPTIDX_BANKNIFTY_CE_01-Apr-2025_TO_30-Jun-2025.csv\n",
      "  4. OPTIDX_BANKNIFTY_CE_01-Jan-2023_TO_31-Mar-2023.csv\n",
      "  5. OPTIDX_BANKNIFTY_CE_01-Jan-2024_TO_31-Mar-2024.csv\n",
      "  6. OPTIDX_BANKNIFTY_CE_01-Jan-2025_TO_31-Mar-2025.csv\n",
      "  7. OPTIDX_BANKNIFTY_CE_01-Jul-2023_TO_30-Sep-2023.csv\n",
      "  8. OPTIDX_BANKNIFTY_CE_01-Jul-2024_TO_30-Sep-2024.csv\n",
      "  9. OPTIDX_BANKNIFTY_CE_01-Jul-2025_TO_27-Jul-2025.csv\n",
      "  10. OPTIDX_BANKNIFTY_CE_01-Oct-2023_TO_31-Dec-2023.csv\n",
      "  11. OPTIDX_BANKNIFTY_CE_01-Oct-2024_TO_31-Dec-2024.csv\n",
      "  12. OPTIDX_BANKNIFTY_PE_01-Apr-2023_TO_30-Jun-2023.csv\n",
      "  13. OPTIDX_BANKNIFTY_PE_01-Apr-2024_TO_30-Jun-2024.csv\n",
      "  14. OPTIDX_BANKNIFTY_PE_01-Apr-2025_TO_30-Jun-2025.csv\n",
      "  15. OPTIDX_BANKNIFTY_PE_01-Jan-2023_TO_31-Mar-2023.csv\n",
      "  16. OPTIDX_BANKNIFTY_PE_01-Jan-2024_TO_31-Mar-2024.csv\n",
      "  17. OPTIDX_BANKNIFTY_PE_01-Jan-2025_TO_31-Mar-2025.csv\n",
      "  18. OPTIDX_BANKNIFTY_PE_01-Jul-2023_TO_30-Sep-2023.csv\n",
      "  19. OPTIDX_BANKNIFTY_PE_01-Jul-2024_TO_30-Sep-2024.csv\n",
      "  20. OPTIDX_BANKNIFTY_PE_01-Jul-2025_TO_27-Jul-2025.csv\n",
      "  21. OPTIDX_BANKNIFTY_PE_01-Oct-2023_TO_31-Dec-2023.csv\n",
      "  22. OPTIDX_BANKNIFTY_PE_01-Oct-2024_TO_31-Dec-2024.csv\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Apr-2023_TO_30-Jun-2023.csv - 37904 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Apr-2024_TO_30-Jun-2024.csv - 47348 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Apr-2025_TO_30-Jun-2025.csv - 30938 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Jan-2023_TO_31-Mar-2023.csv - 36324 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Jan-2024_TO_31-Mar-2024.csv - 45794 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Jan-2025_TO_31-Mar-2025.csv - 27102 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Jul-2023_TO_30-Sep-2023.csv - 38680 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Jul-2024_TO_30-Sep-2024.csv - 49793 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Jul-2025_TO_27-Jul-2025.csv - 8358 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Oct-2023_TO_31-Dec-2023.csv - 40271 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_CE_01-Oct-2024_TO_31-Dec-2024.csv - 32568 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Apr-2023_TO_30-Jun-2023.csv - 37905 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Apr-2024_TO_30-Jun-2024.csv - 47352 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Apr-2025_TO_30-Jun-2025.csv - 30940 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Jan-2023_TO_31-Mar-2023.csv - 36343 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Jan-2024_TO_31-Mar-2024.csv - 45808 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Jan-2025_TO_31-Mar-2025.csv - 27102 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Jul-2023_TO_30-Sep-2023.csv - 38743 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Jul-2024_TO_30-Sep-2024.csv - 49835 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Jul-2025_TO_27-Jul-2025.csv - 8377 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Oct-2023_TO_31-Dec-2023.csv - 40333 records\n",
      "‚úÖ Loaded: OPTIDX_BANKNIFTY_PE_01-Oct-2024_TO_31-Dec-2024.csv - 32568 records\n",
      "\n",
      "üìä MERGED DATASET SUMMARY:\n",
      "------------------------------\n",
      "üìà Total Options Records: 790,386\n",
      "üìû Call Options (CE): 395,080\n",
      "üìâ Put Options (PE): 395,306\n",
      "üìÖ Date Range: 02-Jan-2023 to 25-Jul-2025\n",
      "üéØ Expiry Range: 05-Jan-2023 to 30-Jun-2026\n",
      "üìã Unique Expiries: 128\n",
      "üìÑ Source Files: 22\n",
      "\n",
      "üìã DATASET COLUMNS:\n",
      "--------------------\n",
      "   1. Symbol\n",
      "   2. Date\n",
      "   3. Expiry\n",
      "   4. Option type\n",
      "   5. Strike Price\n",
      "   6. Open\n",
      "   7. High\n",
      "   8. Low\n",
      "   9. Close\n",
      "  10. LTP\n",
      "  11. Settle Price\n",
      "  12. No. of contracts\n",
      "  13. Turnover * in  ‚Çπ Lakhs\n",
      "  14. Premium Turnover ** in   ‚Çπ Lakhs\n",
      "  15. Open Int\n",
      "  16. Change in OI\n",
      "  17. Underlying Value\n",
      "  18. Source_File\n",
      "\n",
      "üîç DATA QUALITY CHECK:\n",
      "-------------------------\n",
      "‚úÖ Missing Values Summary (after replacing '-' with NaN):\n",
      "   Open: 398,835 missing values (50.5%)\n",
      "   High: 398,835 missing values (50.5%)\n",
      "   Low: 398,835 missing values (50.5%)\n",
      "   LTP: 297,296 missing values (37.6%)\n",
      "   Settle Price: 1,630 missing values (0.2%)\n",
      "   No. of contracts: 398,835 missing values (50.5%)\n",
      "   Turnover * in  ‚Çπ Lakhs: 398,835 missing values (50.5%)\n",
      "   Premium Turnover ** in   ‚Çπ Lakhs: 400,166 missing values (50.6%)\n",
      "   Open Int: 301,587 missing values (38.2%)\n",
      "   Change in OI: 413,702 missing values (52.3%)\n",
      "   Underlying Value: 172,840 missing values (21.9%)\n",
      "‚ö†Ô∏è Found 784748 potential duplicate records\n",
      "\n",
      "üìä EXPIRY BREAKDOWN:\n",
      "--------------------\n",
      "  05-Jan-2023: 616 records\n",
      "  12-Jan-2023: 1386 records\n",
      "  19-Jan-2023: 2016 records\n",
      "  25-Jan-2023: 3852 records\n",
      "  02-Feb-2023: 3456 records\n",
      "  09-Feb-2023: 3314 records\n",
      "  16-Feb-2023: 3566 records\n",
      "  23-Feb-2023: 6572 records\n",
      "  02-Mar-2023: 4684 records\n",
      "  09-Mar-2023: 3164 records\n",
      "  16-Mar-2023: 3212 records\n",
      "  23-Mar-2023: 3406 records\n",
      "  29-Mar-2023: 11448 records\n",
      "  06-Apr-2023: 3310 records\n",
      "  13-Apr-2023: 3400 records\n",
      "  20-Apr-2023: 3172 records\n",
      "  27-Apr-2023: 9478 records\n",
      "  04-May-2023: 4378 records\n",
      "  11-May-2023: 3686 records\n",
      "  18-May-2023: 3548 records\n",
      "  25-May-2023: 10472 records\n",
      "  01-Jun-2023: 4738 records\n",
      "  08-Jun-2023: 4000 records\n",
      "  15-Jun-2023: 3636 records\n",
      "  22-Jun-2023: 3630 records\n",
      "  28-Jun-2023: 228 records\n",
      "  29-Jun-2023: 13854 records\n",
      "  06-Jul-2023: 3554 records\n",
      "  13-Jul-2023: 3618 records\n",
      "  20-Jul-2023: 3792 records\n",
      "  27-Jul-2023: 10672 records\n",
      "  03-Aug-2023: 4874 records\n",
      "  10-Aug-2023: 3916 records\n",
      "  17-Aug-2023: 3842 records\n",
      "  24-Aug-2023: 3792 records\n",
      "  31-Aug-2023: 11478 records\n",
      "  06-Sep-2023: 456 records\n",
      "  07-Sep-2023: 2952 records\n",
      "  13-Sep-2023: 1210 records\n",
      "  14-Sep-2023: 2112 records\n",
      "  20-Sep-2023: 1906 records\n",
      "  21-Sep-2023: 1522 records\n",
      "  28-Sep-2023: 14633 records\n",
      "  04-Oct-2023: 3448 records\n",
      "  05-Oct-2023: 822 records\n",
      "  11-Oct-2023: 3758 records\n",
      "  18-Oct-2023: 3760 records\n",
      "  26-Oct-2023: 10214 records\n",
      "  01-Nov-2023: 4590 records\n",
      "  08-Nov-2023: 3756 records\n",
      "  15-Nov-2023: 3908 records\n",
      "  22-Nov-2023: 3842 records\n",
      "  30-Nov-2023: 11250 records\n",
      "  06-Dec-2023: 3906 records\n",
      "  13-Dec-2023: 3884 records\n",
      "  20-Dec-2023: 4286 records\n",
      "  28-Dec-2023: 16614 records\n",
      "  03-Jan-2024: 5608 records\n",
      "  10-Jan-2024: 3748 records\n",
      "  17-Jan-2024: 3880 records\n",
      "  25-Jan-2024: 13398 records\n",
      "  31-Jan-2024: 4978 records\n",
      "  07-Feb-2024: 4754 records\n",
      "  14-Feb-2024: 5024 records\n",
      "  21-Feb-2024: 4358 records\n",
      "  29-Feb-2024: 13260 records\n",
      "  06-Mar-2024: 4922 records\n",
      "  13-Mar-2024: 4946 records\n",
      "  20-Mar-2024: 4678 records\n",
      "  27-Mar-2024: 4104 records\n",
      "  28-Mar-2024: 13978 records\n",
      "  03-Apr-2024: 5288 records\n",
      "  10-Apr-2024: 4124 records\n",
      "  16-Apr-2024: 3854 records\n",
      "  24-Apr-2024: 7838 records\n",
      "  25-Apr-2024: 4498 records\n",
      "  30-Apr-2024: 4928 records\n",
      "  08-May-2024: 4256 records\n",
      "  15-May-2024: 4370 records\n",
      "  22-May-2024: 4744 records\n",
      "  29-May-2024: 12496 records\n",
      "  05-Jun-2024: 4918 records\n",
      "  12-Jun-2024: 4924 records\n",
      "  19-Jun-2024: 4992 records\n",
      "  26-Jun-2024: 13626 records\n",
      "  27-Jun-2024: 4350 records\n",
      "  03-Jul-2024: 6814 records\n",
      "  10-Jul-2024: 5064 records\n",
      "  16-Jul-2024: 4800 records\n",
      "  24-Jul-2024: 4484 records\n",
      "  31-Jul-2024: 15902 records\n",
      "  07-Aug-2024: 4502 records\n",
      "  14-Aug-2024: 4550 records\n",
      "  21-Aug-2024: 4748 records\n",
      "  28-Aug-2024: 16550 records\n",
      "  04-Sep-2024: 5510 records\n",
      "  11-Sep-2024: 4470 records\n",
      "  18-Sep-2024: 4644 records\n",
      "  25-Sep-2024: 15858 records\n",
      "  26-Sep-2024: 2710 records\n",
      "  01-Oct-2024: 5604 records\n",
      "  09-Oct-2024: 5024 records\n",
      "  16-Oct-2024: 5180 records\n",
      "  23-Oct-2024: 5108 records\n",
      "  30-Oct-2024: 14004 records\n",
      "  06-Nov-2024: 5106 records\n",
      "  13-Nov-2024: 4562 records\n",
      "  27-Nov-2024: 13828 records\n",
      "  24-Dec-2024: 18344 records\n",
      "  26-Dec-2024: 1098 records\n",
      "  29-Jan-2025: 8816 records\n",
      "  30-Jan-2025: 5638 records\n",
      "  26-Feb-2025: 4644 records\n",
      "  27-Feb-2025: 11630 records\n",
      "  26-Mar-2025: 5686 records\n",
      "  27-Mar-2025: 15778 records\n",
      "  24-Apr-2025: 15282 records\n",
      "  29-May-2025: 18888 records\n",
      "  25-Jun-2025: 3370 records\n",
      "  26-Jun-2025: 21260 records\n",
      "  31-Jul-2025: 18078 records\n",
      "  28-Aug-2025: 10366 records\n",
      "  24-Sep-2025: 1732 records\n",
      "  25-Sep-2025: 8642 records\n",
      "  24-Dec-2025: 3901 records\n",
      "  31-Dec-2025: 110 records\n",
      "  26-Mar-2026: 2208 records\n",
      "  30-Jun-2026: 462 records\n",
      "\n",
      "‚úÖ Successfully loaded and separated Bank Nifty options data!\n",
      "üìä Datasets available:\n",
      "   üìû Call Options (CE): 395,080 records\n",
      "   üìâ Put Options (PE): 395,306 records\n",
      "   üìã Total Options: 790,386 records\n",
      "\n",
      "üìä DATA LOADING RESULTS:\n",
      "------------------------------\n",
      "‚úÖ CALL OPTIONS:\n",
      "   üìà Records: 395,080\n",
      "   üìÖ Date range: 2023-01-02 00:00:00 to 2025-07-25 00:00:00\n",
      "   üí∞ Strike range: ‚Çπ25,500 - ‚Çπ65,000\n",
      "   üìã Columns: ['Symbol', 'Date', 'Expiry', 'Option type', 'Strike Price', 'Open', 'High', 'Low', 'Close', 'LTP', 'Settle Price', 'No. of contracts', 'Turnover * in  ‚Çπ Lakhs', 'Premium Turnover ** in   ‚Çπ Lakhs', 'Open Int', 'Change in OI', 'Underlying Value', 'Source_File']\n",
      "\n",
      "üîç CALL OPTIONS SAMPLE DATA (First 3 records):\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Expiry</th>\n",
       "      <th>Option type</th>\n",
       "      <th>Strike Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>LTP</th>\n",
       "      <th>Settle Price</th>\n",
       "      <th>No. of contracts</th>\n",
       "      <th>Turnover * in  ‚Çπ Lakhs</th>\n",
       "      <th>Premium Turnover ** in   ‚Çπ Lakhs</th>\n",
       "      <th>Open Int</th>\n",
       "      <th>Change in OI</th>\n",
       "      <th>Underlying Value</th>\n",
       "      <th>Source_File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BANKNIFTY</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>CE</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.95</td>\n",
       "      <td>108278.0</td>\n",
       "      <td>1299421.71</td>\n",
       "      <td>85.71</td>\n",
       "      <td>402600.0</td>\n",
       "      <td>17325.0</td>\n",
       "      <td>43203.10</td>\n",
       "      <td>OPTIDX_BANKNIFTY_CE_01-Jan-2023_TO_31-Mar-2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BANKNIFTY</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>CE</td>\n",
       "      <td>48500.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.70</td>\n",
       "      <td>66529.0</td>\n",
       "      <td>806713.77</td>\n",
       "      <td>49.64</td>\n",
       "      <td>183850.0</td>\n",
       "      <td>37975.0</td>\n",
       "      <td>43203.10</td>\n",
       "      <td>OPTIDX_BANKNIFTY_CE_01-Jan-2023_TO_31-Mar-2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANKNIFTY</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>CE</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>708.00</td>\n",
       "      <td>944.10</td>\n",
       "      <td>609.40</td>\n",
       "      <td>790.45</td>\n",
       "      <td>831.35</td>\n",
       "      <td>790.45</td>\n",
       "      <td>67897.0</td>\n",
       "      <td>734630.01</td>\n",
       "      <td>13224.39</td>\n",
       "      <td>220125.0</td>\n",
       "      <td>-35150.0</td>\n",
       "      <td>43203.10</td>\n",
       "      <td>OPTIDX_BANKNIFTY_CE_01-Jan-2023_TO_31-Mar-2023...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol       Date     Expiry Option type  Strike Price    Open    High  \\\n",
       "0  BANKNIFTY 2023-01-02 2023-01-05          CE       48000.0    4.05    4.25   \n",
       "1  BANKNIFTY 2023-01-02 2023-01-05          CE       48500.0    3.35    3.70   \n",
       "2  BANKNIFTY 2023-01-02 2023-01-05          CE       42500.0  708.00  944.10   \n",
       "\n",
       "      Low   Close     LTP Settle Price  No. of contracts  \\\n",
       "0    2.70    2.95    2.70         2.95          108278.0   \n",
       "1    2.55    2.70    2.65         2.70           66529.0   \n",
       "2  609.40  790.45  831.35       790.45           67897.0   \n",
       "\n",
       "  Turnover * in  ‚Çπ Lakhs Premium Turnover ** in   ‚Çπ Lakhs  Open Int  \\\n",
       "0             1299421.71                            85.71  402600.0   \n",
       "1              806713.77                            49.64  183850.0   \n",
       "2              734630.01                         13224.39  220125.0   \n",
       "\n",
       "   Change in OI Underlying Value  \\\n",
       "0       17325.0         43203.10   \n",
       "1       37975.0         43203.10   \n",
       "2      -35150.0         43203.10   \n",
       "\n",
       "                                         Source_File  \n",
       "0  OPTIDX_BANKNIFTY_CE_01-Jan-2023_TO_31-Mar-2023...  \n",
       "1  OPTIDX_BANKNIFTY_CE_01-Jan-2023_TO_31-Mar-2023...  \n",
       "2  OPTIDX_BANKNIFTY_CE_01-Jan-2023_TO_31-Mar-2023...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ PUT OPTIONS:\n",
      "   üìâ Records: 395,306\n",
      "   üìÖ Date range: 2023-01-02 00:00:00 to 2025-07-25 00:00:00\n",
      "   üí∞ Strike range: ‚Çπ25,500 - ‚Çπ65,000\n",
      "   üìã Columns: ['Symbol', 'Date', 'Expiry', 'Option type', 'Strike Price', 'Open', 'High', 'Low', 'Close', 'LTP', 'Settle Price', 'No. of contracts', 'Turnover * in  ‚Çπ Lakhs', 'Premium Turnover ** in   ‚Çπ Lakhs', 'Open Int', 'Change in OI', 'Underlying Value', 'Source_File']\n",
      "\n",
      "üîç PUT OPTIONS SAMPLE DATA (First 3 records):\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Expiry</th>\n",
       "      <th>Option type</th>\n",
       "      <th>Strike Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>LTP</th>\n",
       "      <th>Settle Price</th>\n",
       "      <th>No. of contracts</th>\n",
       "      <th>Turnover * in  ‚Çπ Lakhs</th>\n",
       "      <th>Premium Turnover ** in   ‚Çπ Lakhs</th>\n",
       "      <th>Open Int</th>\n",
       "      <th>Change in OI</th>\n",
       "      <th>Underlying Value</th>\n",
       "      <th>Source_File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BANKNIFTY</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>PE</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.55</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.95</td>\n",
       "      <td>367120.0</td>\n",
       "      <td>3671721.29</td>\n",
       "      <td>521.29</td>\n",
       "      <td>1507800.0</td>\n",
       "      <td>-237800.0</td>\n",
       "      <td>43203.10</td>\n",
       "      <td>OPTIDX_BANKNIFTY_PE_01-Jan-2023_TO_31-Mar-2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BANKNIFTY</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>PE</td>\n",
       "      <td>40400.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.85</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.70</td>\n",
       "      <td>33862.0</td>\n",
       "      <td>342062.80</td>\n",
       "      <td>56.60</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>-3050.0</td>\n",
       "      <td>43203.10</td>\n",
       "      <td>OPTIDX_BANKNIFTY_PE_01-Jan-2023_TO_31-Mar-2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANKNIFTY</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>PE</td>\n",
       "      <td>43600.0</td>\n",
       "      <td>643.8</td>\n",
       "      <td>715.00</td>\n",
       "      <td>403.25</td>\n",
       "      <td>496.90</td>\n",
       "      <td>461.55</td>\n",
       "      <td>496.90</td>\n",
       "      <td>210140.0</td>\n",
       "      <td>2316823.96</td>\n",
       "      <td>26297.96</td>\n",
       "      <td>198775.0</td>\n",
       "      <td>91475.0</td>\n",
       "      <td>43203.10</td>\n",
       "      <td>OPTIDX_BANKNIFTY_PE_01-Jan-2023_TO_31-Mar-2023...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol       Date     Expiry Option type  Strike Price   Open    High  \\\n",
       "0  BANKNIFTY 2023-01-02 2023-01-05          PE       40000.0    6.1    7.55   \n",
       "1  BANKNIFTY 2023-01-02 2023-01-05          PE       40400.0   10.0   10.00   \n",
       "2  BANKNIFTY 2023-01-02 2023-01-05          PE       43600.0  643.8  715.00   \n",
       "\n",
       "      Low   Close     LTP Settle Price  No. of contracts  \\\n",
       "0    4.60    4.95    4.80         4.95          367120.0   \n",
       "1    4.85    5.70    5.75         5.70           33862.0   \n",
       "2  403.25  496.90  461.55       496.90          210140.0   \n",
       "\n",
       "  Turnover * in  ‚Çπ Lakhs Premium Turnover ** in   ‚Çπ Lakhs   Open Int  \\\n",
       "0             3671721.29                           521.29  1507800.0   \n",
       "1              342062.80                            56.60    79450.0   \n",
       "2             2316823.96                         26297.96   198775.0   \n",
       "\n",
       "   Change in OI Underlying Value  \\\n",
       "0     -237800.0         43203.10   \n",
       "1       -3050.0         43203.10   \n",
       "2       91475.0         43203.10   \n",
       "\n",
       "                                         Source_File  \n",
       "0  OPTIDX_BANKNIFTY_PE_01-Jan-2023_TO_31-Mar-2023...  \n",
       "1  OPTIDX_BANKNIFTY_PE_01-Jan-2023_TO_31-Mar-2023...  \n",
       "2  OPTIDX_BANKNIFTY_PE_01-Jan-2023_TO_31-Mar-2023...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ MERGED OPTIONS DATA:\n",
      "   üîÑ Total records: 790,386\n",
      "   üìä Shape: (790386, 18)\n",
      "\n",
      "üéØ DATA VARIABLES CREATED:\n",
      "-------------------------\n",
      "   ‚Ä¢ df_call: Call options DataFrame\n",
      "   ‚Ä¢ df_put: Put options DataFrame\n",
      "   ‚Ä¢ options_merged: Combined options DataFrame\n",
      "\n",
      "‚úÖ Options data loading completed successfully!\n",
      "\n",
      "üìà NEXT STEP: Load Bank Nifty spot data for XGBoost modeling\n"
     ]
    }
   ],
   "source": [
    "# üìä LOAD BANK NIFTY OPTIONS DATA\n",
    "# Load Bank Nifty Options Data using the options_data_loader module\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"üöÄ LOADING BANK NIFTY OPTIONS DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Setup path to import custom modules\n",
    "current_dir = os.getcwd()\n",
    "if 'notebooks' in current_dir:\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(f\"üìÇ Project root: {project_root}\")\n",
    "print(f\"üîß Source path: {src_path}\")\n",
    "\n",
    "# Import the options data loader\n",
    "try:\n",
    "    from utils.options_data_loader import load_banknifty_options_data\n",
    "    print(\"‚úÖ Successfully imported options_data_loader\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import options_data_loader: {e}\")\n",
    "    print(\"üí° Make sure the src/utils/options_data_loader.py file exists\")\n",
    "    raise\n",
    "\n",
    "# Load the options data using the dedicated function\n",
    "data_path = os.path.join(project_root, 'data')\n",
    "print(f\"üìÅ Data path: {data_path}\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nüîÑ Loading Bank Nifty options data...\")\n",
    "    df_call, df_put, options_merged = load_banknifty_options_data(data_path)\n",
    "    \n",
    "    print(f\"\\nüìä DATA LOADING RESULTS:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if not df_call.empty:\n",
    "        print(f\"‚úÖ CALL OPTIONS:\")\n",
    "        print(f\"   üìà Records: {len(df_call):,}\")\n",
    "        print(f\"   üìÖ Date range: {df_call['Date'].min()} to {df_call['Date'].max()}\")\n",
    "        print(f\"   üí∞ Strike range: ‚Çπ{df_call['Strike Price'].min():,.0f} - ‚Çπ{df_call['Strike Price'].max():,.0f}\")\n",
    "        print(f\"   üìã Columns: {list(df_call.columns)}\")\n",
    "        \n",
    "        print(f\"\\nüîç CALL OPTIONS SAMPLE DATA (First 3 records):\")\n",
    "        print(\"-\" * 45)\n",
    "        display(df_call.head(3))\n",
    "    else:\n",
    "        print(\"‚ùå No call options data loaded\")\n",
    "    \n",
    "    if not df_put.empty:\n",
    "        print(f\"\\n‚úÖ PUT OPTIONS:\")\n",
    "        print(f\"   üìâ Records: {len(df_put):,}\")\n",
    "        print(f\"   üìÖ Date range: {df_put['Date'].min()} to {df_put['Date'].max()}\")\n",
    "        print(f\"   üí∞ Strike range: ‚Çπ{df_put['Strike Price'].min():,.0f} - ‚Çπ{df_put['Strike Price'].max():,.0f}\")\n",
    "        print(f\"   üìã Columns: {list(df_put.columns)}\")\n",
    "        \n",
    "        print(f\"\\nüîç PUT OPTIONS SAMPLE DATA (First 3 records):\")\n",
    "        print(\"-\" * 44)\n",
    "        display(df_put.head(3))\n",
    "    else:\n",
    "        print(\"‚ùå No put options data loaded\")\n",
    "    \n",
    "    if not options_merged.empty:\n",
    "        print(f\"\\n‚úÖ MERGED OPTIONS DATA:\")\n",
    "        print(f\"   üîÑ Total records: {len(options_merged):,}\")\n",
    "        print(f\"   üìä Shape: {options_merged.shape}\")\n",
    "    else:\n",
    "        print(\"‚ùå No merged options data available\")\n",
    "        \n",
    "    print(f\"\\nüéØ DATA VARIABLES CREATED:\")\n",
    "    print(\"-\" * 25)\n",
    "    print(\"   ‚Ä¢ df_call: Call options DataFrame\")\n",
    "    print(\"   ‚Ä¢ df_put: Put options DataFrame\") \n",
    "    print(\"   ‚Ä¢ options_merged: Combined options DataFrame\")\n",
    "    print(f\"\\n‚úÖ Options data loading completed successfully!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading options data: {str(e)}\")\n",
    "    # Initialize empty DataFrames in case of error\n",
    "    df_call = pd.DataFrame()\n",
    "    df_put = pd.DataFrame()\n",
    "    options_merged = pd.DataFrame()\n",
    "    print(\"üîß Initialized empty DataFrames as fallback\")\n",
    "\n",
    "print(f\"\\nüìà NEXT STEP: Load Bank Nifty spot data for XGBoost modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479125fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà LOADING BANK NIFTY SPOT DATA\n",
      "========================================\n",
      "‚úÖ Successfully imported spot_data_loader\n",
      "\n",
      "üîÑ Loading Bank Nifty spot data using load_spot_data...\n",
      "üîÑ Symbol mapping: BANKNIFTY ‚Üí ^NSEBANK\n",
      "üîç Loading spot data for symbol: BANKNIFTY (Yahoo Finance: ^NSEBANK)\n",
      "üìÇ Loading existing spot data from file...\n",
      "‚úÖ Loaded spot data from: BANKNIFTY_yfinance.csv\n",
      "üìã Data Shape: (629, 6)\n",
      "üìÖ Date Range: 02-Jan-2023 to 25-Jul-2025\n",
      "üìä Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "\n",
      "‚úÖ BANK NIFTY SPOT DATA LOADED:\n",
      "-----------------------------------\n",
      "   üìä Records: 629\n",
      "   üìÖ Date range: 02-Jan-2023 to 25-Jul-2025\n",
      "   üí∞ Price range: ‚Çπ39,052 - ‚Çπ57,459\n",
      "   üìã Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "\n",
      "üîç BANK NIFTY SAMPLE DATA (Latest 5 records):\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>56952.750000</td>\n",
       "      <td>56983.449219</td>\n",
       "      <td>56255.699219</td>\n",
       "      <td>56558.898438</td>\n",
       "      <td>133700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>2025-07-22</td>\n",
       "      <td>56756.000000</td>\n",
       "      <td>57286.148438</td>\n",
       "      <td>56692.000000</td>\n",
       "      <td>57253.351562</td>\n",
       "      <td>132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2025-07-23</td>\n",
       "      <td>57210.449219</td>\n",
       "      <td>57249.000000</td>\n",
       "      <td>56715.800781</td>\n",
       "      <td>56918.148438</td>\n",
       "      <td>129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>2025-07-24</td>\n",
       "      <td>57066.050781</td>\n",
       "      <td>57316.601562</td>\n",
       "      <td>56850.898438</td>\n",
       "      <td>57316.601562</td>\n",
       "      <td>179800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>56528.898438</td>\n",
       "      <td>57170.699219</td>\n",
       "      <td>56439.398438</td>\n",
       "      <td>57170.699219</td>\n",
       "      <td>125100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date         Close          High           Low          Open  Volume\n",
       "624 2025-07-21  56952.750000  56983.449219  56255.699219  56558.898438  133700\n",
       "625 2025-07-22  56756.000000  57286.148438  56692.000000  57253.351562  132800\n",
       "626 2025-07-23  57210.449219  57249.000000  56715.800781  56918.148438  129800\n",
       "627 2025-07-24  57066.050781  57316.601562  56850.898438  57316.601562  179800\n",
       "628 2025-07-25  56528.898438  57170.699219  56439.398438  57170.699219  125100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ DATA VARIABLE CREATED:\n",
      "   ‚Ä¢ bank_nifty: Bank Nifty spot price DataFrame\n",
      "\n",
      "‚úÖ Bank Nifty data loaded successfully!\n",
      "\n",
      "üìã DATA LOADING SUMMARY\n",
      "------------------------------\n",
      "‚úÖ Call Options: Loaded (395,080 records)\n",
      "‚úÖ Put Options: Loaded (395,306 records)\n",
      "‚úÖ Bank Nifty Spot: Loaded (629 records)\n",
      "\n",
      "üöÄ ALL DATA LOADED - READY FOR XGBOOST MODELING!\n",
      "üí° You can now proceed to run the XGBoost feature engineering and training cells\n"
     ]
    }
   ],
   "source": [
    "# üìà LOAD BANK NIFTY SPOT DATA\n",
    "# Load Bank Nifty Index data using the flexible spot_data_loader module\n",
    "\n",
    "print(\"üìà LOADING BANK NIFTY SPOT DATA\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Import the Spot data loader\n",
    "try:\n",
    "    from utils.spot_data_loader import load_spot_data\n",
    "    print(\"‚úÖ Successfully imported spot_data_loader\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import spot_data_loader: {e}\")\n",
    "    print(\"üí° Make sure the src/utils/spot_data_loader.py file exists\")\n",
    "    raise\n",
    "\n",
    "# Load Bank Nifty data using the flexible load_spot_data function\n",
    "try:\n",
    "    print(\"\\nüîÑ Loading Bank Nifty spot data using load_spot_data...\")\n",
    "    bank_nifty = load_spot_data(\n",
    "        symbol=\"BANKNIFTY\",  # Uses predefined mapping to ^NSEBANK\n",
    "        data_path=data_path,\n",
    "        start_date=\"2023-01-01\",\n",
    "        end_date=None,  # Download up to current date\n",
    "        force_download=False,  # Use cached data if available\n",
    "        plot_data=False  # Skip plotting for XGBoost workflow\n",
    "    )\n",
    "    \n",
    "    if not bank_nifty.empty:\n",
    "        print(f\"\\n‚úÖ BANK NIFTY SPOT DATA LOADED:\")\n",
    "        print(\"-\" * 35)\n",
    "        print(f\"   üìä Records: {len(bank_nifty):,}\")\n",
    "        print(f\"   üìÖ Date range: {bank_nifty['Date'].min():%d-%b-%Y} to {bank_nifty['Date'].max():%d-%b-%Y}\")\n",
    "        print(f\"   üí∞ Price range: ‚Çπ{bank_nifty['Close'].min():,.0f} - ‚Çπ{bank_nifty['Close'].max():,.0f}\")\n",
    "        print(f\"   üìã Columns: {list(bank_nifty.columns)}\")\n",
    "        \n",
    "        print(f\"\\nüîç BANK NIFTY SAMPLE DATA (Latest 5 records):\")\n",
    "        print(\"-\" * 45)\n",
    "        display(bank_nifty.tail(5))\n",
    "        \n",
    "        print(f\"\\nüéØ DATA VARIABLE CREATED:\")\n",
    "        print(\"   ‚Ä¢ bank_nifty: Bank Nifty spot price DataFrame\")\n",
    "        print(f\"\\n‚úÖ Bank Nifty data loaded successfully!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Failed to load Bank Nifty data\")\n",
    "        bank_nifty = pd.DataFrame()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading Bank Nifty data: {str(e)}\")\n",
    "    bank_nifty = pd.DataFrame()\n",
    "\n",
    "# Data validation summary\n",
    "print(f\"\\nüìã DATA LOADING SUMMARY\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"‚úÖ Call Options: {'Loaded' if not df_call.empty else 'Failed'} ({len(df_call):,} records)\")\n",
    "print(f\"‚úÖ Put Options: {'Loaded' if not df_put.empty else 'Failed'} ({len(df_put):,} records)\")\n",
    "print(f\"‚úÖ Bank Nifty Spot: {'Loaded' if not bank_nifty.empty else 'Failed'} ({len(bank_nifty):,} records)\")\n",
    "\n",
    "if not df_call.empty and not df_put.empty and not bank_nifty.empty:\n",
    "    print(f\"\\nüöÄ ALL DATA LOADED - READY FOR XGBOOST MODELING!\")\n",
    "    print(\"üí° You can now proceed to run the XGBoost feature engineering and training cells\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Some data failed to load. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b177d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß SIMPLE FEATURE ENGINEERING\n",
      "========================================\n",
      "‚úÖ Data available. Starting feature engineering...\n",
      "üìÖ Processing 637 dates...\n",
      "\n",
      "‚úÖ FEATURE ENGINEERING COMPLETED\n",
      "-----------------------------------\n",
      "üìä Total records: 628\n",
      "üîß Total features: 17\n",
      "üìÖ Date range: 2023-01-02 00:00:00 to 2025-07-24 00:00:00\n",
      "\n",
      "üîç SAMPLE FEATURES (First 3 rows):\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>spot_price</th>\n",
       "      <th>target_spot_price</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>pcr_volume</th>\n",
       "      <th>call_atm_ltp</th>\n",
       "      <th>put_atm_ltp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>43203.101562</td>\n",
       "      <td>43425.250000</td>\n",
       "      <td>56770323.0</td>\n",
       "      <td>0.965700</td>\n",
       "      <td>313.00</td>\n",
       "      <td>233.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>43425.250000</td>\n",
       "      <td>42958.800781</td>\n",
       "      <td>62232533.0</td>\n",
       "      <td>0.892912</td>\n",
       "      <td>0.00</td>\n",
       "      <td>176.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>42958.800781</td>\n",
       "      <td>42608.699219</td>\n",
       "      <td>121250162.0</td>\n",
       "      <td>1.122982</td>\n",
       "      <td>1603.15</td>\n",
       "      <td>1152.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    spot_price  target_spot_price  total_volume  pcr_volume  \\\n",
       "0 2023-01-02  43203.101562       43425.250000    56770323.0    0.965700   \n",
       "1 2023-01-03  43425.250000       42958.800781    62232533.0    0.892912   \n",
       "2 2023-01-04  42958.800781       42608.699219   121250162.0    1.122982   \n",
       "\n",
       "   call_atm_ltp  put_atm_ltp  \n",
       "0        313.00       233.15  \n",
       "1          0.00       176.30  \n",
       "2       1603.15      1152.35  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ FEATURES SAVED TO CSV\n",
      "-------------------------\n",
      "üìÅ File: c:\\Users\\91894\\Projects\\market-data\\data\\engineered_features.csv\n",
      "üìä Records saved: 628\n",
      "üîß Features saved: 19\n",
      "\n",
      "üìã FEATURE SUMMARY\n",
      "--------------------\n",
      " 1. spot_price          : Avg = 48051.79\n",
      " 2. call_total_volume   : Avg = 72625409.92\n",
      " 3. call_total_oi       : Avg = 54103409.91\n",
      " 4. call_avg_ltp        : Avg =  1059.17\n",
      " 5. call_max_ltp        : Avg = 10914.98\n",
      " 6. call_count          : Avg =   620.27\n",
      " 7. put_total_volume    : Avg = 67767719.41\n",
      " 8. put_total_oi        : Avg = 46857108.48\n",
      " 9. put_avg_ltp         : Avg =   702.83\n",
      "10. put_max_ltp         : Avg =  8300.36\n",
      "11. put_count           : Avg =   620.63\n",
      "12. total_volume        : Avg = 140393129.32\n",
      "13. total_oi            : Avg = 100960518.39\n",
      "14. pcr_volume          : Avg =     0.94\n",
      "15. pcr_oi              : Avg =     0.90\n",
      "16. call_atm_ltp        : Avg =   688.15\n",
      "17. put_atm_ltp         : Avg =   513.34\n",
      "\n",
      "‚úÖ Feature engineering completed successfully!\n",
      "üí° You can now use 'features_df' variable for modeling\n",
      "üìÑ CSV file saved for future use: engineered_features.csv\n"
     ]
    }
   ],
   "source": [
    "# üîß SIMPLE FEATURE ENGINEERING\n",
    "# Create features from options data and save to CSV file\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"üîß SIMPLE FEATURE ENGINEERING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Check if data is available\n",
    "if 'df_call' not in globals() or 'df_put' not in globals() or 'bank_nifty' not in globals():\n",
    "    print(\"‚ùå Required data not found. Please run the data loading cells first.\")\n",
    "else:\n",
    "    if df_call.empty or df_put.empty or bank_nifty.empty:\n",
    "        print(\"‚ùå Data is empty. Please check the data loading process.\")\n",
    "    else:\n",
    "        print(\"‚úÖ Data available. Starting feature engineering...\")\n",
    "        \n",
    "        # Create features by date\n",
    "        features_list = []\n",
    "        \n",
    "        # Get unique dates from options data\n",
    "        all_dates = sorted(set(df_call['Date'].unique()) & set(df_put['Date'].unique()))\n",
    "        print(f\"üìÖ Processing {len(all_dates)} dates...\")\n",
    "        \n",
    "        for date in all_dates:\n",
    "            # Get options data for this date\n",
    "            calls_today = df_call[df_call['Date'] == date].copy()\n",
    "            puts_today = df_put[df_put['Date'] == date].copy()\n",
    "            \n",
    "            # Get Bank Nifty spot price for this date\n",
    "            spot_today = bank_nifty[bank_nifty['Date'] == date]\n",
    "            \n",
    "            if spot_today.empty:\n",
    "                continue  # Skip if no spot data for this date\n",
    "            \n",
    "            spot_price = spot_today['Close'].iloc[0]\n",
    "            \n",
    "            # Clean and convert data types to handle mixed data\n",
    "            calls_today = calls_today.copy()\n",
    "            puts_today = puts_today.copy()\n",
    "            \n",
    "            # Convert LTP columns to numeric, handling any non-numeric values\n",
    "            calls_today['LTP'] = pd.to_numeric(calls_today['LTP'], errors='coerce').fillna(0)\n",
    "            puts_today['LTP'] = pd.to_numeric(puts_today['LTP'], errors='coerce').fillna(0)\n",
    "            \n",
    "            # Convert volume and OI columns to numeric\n",
    "            calls_today['No. of contracts'] = pd.to_numeric(calls_today['No. of contracts'], errors='coerce').fillna(0)\n",
    "            puts_today['No. of contracts'] = pd.to_numeric(puts_today['No. of contracts'], errors='coerce').fillna(0)\n",
    "            calls_today['Open Int'] = pd.to_numeric(calls_today['Open Int'], errors='coerce').fillna(0)\n",
    "            puts_today['Open Int'] = pd.to_numeric(puts_today['Open Int'], errors='coerce').fillna(0)\n",
    "            calls_today['Strike Price'] = pd.to_numeric(calls_today['Strike Price'], errors='coerce').fillna(0)\n",
    "            puts_today['Strike Price'] = pd.to_numeric(puts_today['Strike Price'], errors='coerce').fillna(0)\n",
    "            \n",
    "            # Calculate basic features with proper error handling\n",
    "            try:\n",
    "                call_volume_sum = calls_today['No. of contracts'].sum()\n",
    "                call_oi_sum = calls_today['Open Int'].sum()\n",
    "                call_ltp_mean = calls_today['LTP'].mean() if len(calls_today) > 0 else 0\n",
    "                call_ltp_max = calls_today['LTP'].max() if len(calls_today) > 0 else 0\n",
    "                \n",
    "                put_volume_sum = puts_today['No. of contracts'].sum()\n",
    "                put_oi_sum = puts_today['Open Int'].sum()\n",
    "                put_ltp_mean = puts_today['LTP'].mean() if len(puts_today) > 0 else 0\n",
    "                put_ltp_max = puts_today['LTP'].max() if len(puts_today) > 0 else 0\n",
    "                \n",
    "                # ATM options calculation with error handling\n",
    "                call_atm_ltp = 0\n",
    "                put_atm_ltp = 0\n",
    "                \n",
    "                if not calls_today.empty and len(calls_today) > 0:\n",
    "                    try:\n",
    "                        closest_call_idx = (calls_today['Strike Price'] - spot_price).abs().argsort().iloc[0]\n",
    "                        call_atm_ltp = calls_today.iloc[closest_call_idx]['LTP']\n",
    "                    except:\n",
    "                        call_atm_ltp = 0\n",
    "                \n",
    "                if not puts_today.empty and len(puts_today) > 0:\n",
    "                    try:\n",
    "                        closest_put_idx = (puts_today['Strike Price'] - spot_price).abs().argsort().iloc[0]\n",
    "                        put_atm_ltp = puts_today.iloc[closest_put_idx]['LTP']\n",
    "                    except:\n",
    "                        put_atm_ltp = 0\n",
    "                \n",
    "                features = {\n",
    "                    'Date': date,\n",
    "                    'spot_price': spot_price,\n",
    "                    \n",
    "                    # Call features\n",
    "                    'call_total_volume': call_volume_sum,\n",
    "                    'call_total_oi': call_oi_sum,\n",
    "                    'call_avg_ltp': call_ltp_mean,\n",
    "                    'call_max_ltp': call_ltp_max,\n",
    "                    'call_count': len(calls_today),\n",
    "                    \n",
    "                    # Put features  \n",
    "                    'put_total_volume': put_volume_sum,\n",
    "                    'put_total_oi': put_oi_sum,\n",
    "                    'put_avg_ltp': put_ltp_mean,\n",
    "                    'put_max_ltp': put_ltp_max,\n",
    "                    'put_count': len(puts_today),\n",
    "                    \n",
    "                    # Combined features\n",
    "                    'total_volume': call_volume_sum + put_volume_sum,\n",
    "                    'total_oi': call_oi_sum + put_oi_sum,\n",
    "                    \n",
    "                    # Put-Call Ratios\n",
    "                    'pcr_volume': put_volume_sum / max(call_volume_sum, 1),\n",
    "                    'pcr_oi': put_oi_sum / max(call_oi_sum, 1),\n",
    "                    \n",
    "                    # ATM options\n",
    "                    'call_atm_ltp': call_atm_ltp,\n",
    "                    'put_atm_ltp': put_atm_ltp,\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing date {date}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            features_list.append(features)\n",
    "        \n",
    "        # Create features DataFrame\n",
    "        features_df = pd.DataFrame(features_list)\n",
    "        \n",
    "        if not features_df.empty:\n",
    "            # Sort by date\n",
    "            features_df = features_df.sort_values('Date').reset_index(drop=True)\n",
    "            \n",
    "            # Add target variable (next day's spot price)\n",
    "            features_df['target_spot_price'] = features_df['spot_price'].shift(-1)\n",
    "            \n",
    "            # Remove last row (no target available)\n",
    "            features_df = features_df.dropna()\n",
    "            \n",
    "            print(f\"\\n‚úÖ FEATURE ENGINEERING COMPLETED\")\n",
    "            print(\"-\" * 35)\n",
    "            print(f\"üìä Total records: {len(features_df)}\")\n",
    "            print(f\"üîß Total features: {len(features_df.columns) - 2}\")  # Exclude Date and target\n",
    "            print(f\"üìÖ Date range: {features_df['Date'].min()} to {features_df['Date'].max()}\")\n",
    "            \n",
    "            # Display sample features\n",
    "            print(f\"\\nüîç SAMPLE FEATURES (First 3 rows):\")\n",
    "            print(\"-\" * 35)\n",
    "            display_cols = ['Date', 'spot_price', 'target_spot_price', 'total_volume', 'pcr_volume', 'call_atm_ltp', 'put_atm_ltp']\n",
    "            display(features_df[display_cols].head(3))\n",
    "            \n",
    "            # Save to CSV file\n",
    "            output_file = os.path.join(project_root, 'data', 'engineered_features.csv')\n",
    "            features_df.to_csv(output_file, index=False)\n",
    "            \n",
    "            print(f\"\\nüíæ FEATURES SAVED TO CSV\")\n",
    "            print(\"-\" * 25)\n",
    "            print(f\"üìÅ File: {output_file}\")\n",
    "            print(f\"üìä Records saved: {len(features_df)}\")\n",
    "            print(f\"üîß Features saved: {len(features_df.columns)}\")\n",
    "            \n",
    "            # Feature summary\n",
    "            print(f\"\\nüìã FEATURE SUMMARY\")\n",
    "            print(\"-\" * 20)\n",
    "            feature_cols = [col for col in features_df.columns if col not in ['Date', 'target_spot_price']]\n",
    "            \n",
    "            for i, feature in enumerate(feature_cols, 1):\n",
    "                avg_val = features_df[feature].mean()\n",
    "                print(f\"{i:2d}. {feature:<20}: Avg = {avg_val:>8.2f}\")\n",
    "            \n",
    "            print(f\"\\n‚úÖ Feature engineering completed successfully!\")\n",
    "            print(\"üí° You can now use 'features_df' variable for modeling\")\n",
    "            print(f\"üìÑ CSV file saved for future use: engineered_features.csv\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå No features could be created. Check your data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb7d1cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä NEW PREVIOUS DAY FEATURES ADDED TO XGBOOST MODEL\n",
      "============================================================\n",
      "‚úÖ TOTAL NEW LAG FEATURES ADDED: 0\n",
      "---------------------------------------------\n",
      "üí∞ PRICE-BASED LAG FEATURES:\n",
      "\n",
      "üìä VOLUME-BASED LAG FEATURES:\n",
      "\n",
      "üìà MOMENTUM & CHANGE FEATURES:\n",
      "\n",
      "üîß TECHNICAL ANALYSIS FEATURES:\n",
      "\n",
      "üîç SAMPLE VALUES FOR KEY NEW FEATURES (First 3 records):\n",
      "-------------------------------------------------------\n",
      "\n",
      "üìä STATISTICS FOR NEW LAG FEATURES:\n",
      "----------------------------------------\n",
      "\n",
      "üéØ BENEFITS OF THESE NEW FEATURES:\n",
      "-----------------------------------\n",
      "   ‚úÖ Price momentum detection (price_change_pct, momentum_2day)\n",
      "   ‚úÖ Volume trend analysis (volume_ratio, volume_vs_ma5)\n",
      "   ‚úÖ Gap up/down identification (gap_up_down)\n",
      "   ‚úÖ Moving average signals (price_vs_ma5, ma5_close)\n",
      "   ‚úÖ Technical patterns (prev_range, prev_body, shadows)\n",
      "   ‚úÖ Multi-day trend analysis (2day features)\n",
      "\n",
      "üí° EXPECTED MODEL IMPROVEMENTS:\n",
      "   üöÄ Better trend continuation/reversal detection\n",
      "   üìä Enhanced volume-price relationship modeling\n",
      "   üéØ Improved intraday gap prediction\n",
      "   üìà Better handling of market momentum\n",
      "\n",
      "‚úÖ Ready to retrain XGBoost model with enhanced features!\n"
     ]
    }
   ],
   "source": [
    "# üìä NEW FEATURES SUMMARY: Previous Day Spot Price & Volume Features\n",
    "# Display the new lag features that have been added to improve model performance\n",
    "\n",
    "print(\"üìä NEW PREVIOUS DAY FEATURES ADDED TO XGBOOST MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'features_df' in locals() and not features_df.empty:\n",
    "    # List all the new previous day features\n",
    "    lag_features = [col for col in features_df.columns if any(keyword in col.lower() \n",
    "                   for keyword in ['prev', 'ma5', 'momentum', 'gap', 'change_pct', 'volume_ratio'])]\n",
    "    \n",
    "    print(f\"‚úÖ TOTAL NEW LAG FEATURES ADDED: {len(lag_features)}\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    # Categorize the features\n",
    "    price_features = [f for f in lag_features if any(p in f for p in ['prev_close', 'prev_high', 'prev_low', 'prev_open', 'ma5_close'])]\n",
    "    volume_features = [f for f in lag_features if 'volume' in f]\n",
    "    momentum_features = [f for f in lag_features if any(m in f for m in ['change_pct', 'momentum', 'gap'])]\n",
    "    technical_features = [f for f in lag_features if any(t in f for t in ['range', 'body', 'shadow', 'vs_ma5'])]\n",
    "    \n",
    "    print(\"üí∞ PRICE-BASED LAG FEATURES:\")\n",
    "    for i, feature in enumerate(price_features, 1):\n",
    "        print(f\"   {i:2d}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nüìä VOLUME-BASED LAG FEATURES:\")\n",
    "    for i, feature in enumerate(volume_features, 1):\n",
    "        print(f\"   {i:2d}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nüìà MOMENTUM & CHANGE FEATURES:\")\n",
    "    for i, feature in enumerate(momentum_features, 1):\n",
    "        print(f\"   {i:2d}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nüîß TECHNICAL ANALYSIS FEATURES:\")\n",
    "    for i, feature in enumerate(technical_features, 1):\n",
    "        print(f\"   {i:2d}. {feature}\")\n",
    "    \n",
    "    # Show sample values for key new features\n",
    "    print(f\"\\nüîç SAMPLE VALUES FOR KEY NEW FEATURES (First 3 records):\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    key_features = ['prev_close', 'prev_volume', 'price_change_pct', 'volume_ratio', 'gap_up_down', 'ma5_close']\n",
    "    available_key_features = [f for f in key_features if f in features_df.columns]\n",
    "    \n",
    "    if available_key_features:\n",
    "        sample_data = features_df[['Date'] + available_key_features].head(3)\n",
    "        display(sample_data)\n",
    "    \n",
    "    # Show statistics for the new features\n",
    "    print(f\"\\nüìä STATISTICS FOR NEW LAG FEATURES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if 'price_change_pct' in features_df.columns:\n",
    "        price_changes = features_df['price_change_pct']\n",
    "        print(f\"üí∞ Daily Price Changes:\")\n",
    "        print(f\"   Mean: {price_changes.mean():.2f}%\")\n",
    "        print(f\"   Std:  {price_changes.std():.2f}%\")\n",
    "        print(f\"   Min:  {price_changes.min():.2f}%\")\n",
    "        print(f\"   Max:  {price_changes.max():.2f}%\")\n",
    "    \n",
    "    if 'volume_ratio' in features_df.columns:\n",
    "        volume_ratios = features_df['volume_ratio']\n",
    "        print(f\"\\nüìà Volume Ratios (in millions):\")\n",
    "        print(f\"   Mean: {volume_ratios.mean():.2f}M\")\n",
    "        print(f\"   Std:  {volume_ratios.std():.2f}M\")\n",
    "        print(f\"   Min:  {volume_ratios.min():.2f}M\") \n",
    "        print(f\"   Max:  {volume_ratios.max():.2f}M\")\n",
    "    \n",
    "    print(f\"\\nüéØ BENEFITS OF THESE NEW FEATURES:\")\n",
    "    print(\"-\" * 35)\n",
    "    print(\"   ‚úÖ Price momentum detection (price_change_pct, momentum_2day)\")\n",
    "    print(\"   ‚úÖ Volume trend analysis (volume_ratio, volume_vs_ma5)\")\n",
    "    print(\"   ‚úÖ Gap up/down identification (gap_up_down)\")\n",
    "    print(\"   ‚úÖ Moving average signals (price_vs_ma5, ma5_close)\")\n",
    "    print(\"   ‚úÖ Technical patterns (prev_range, prev_body, shadows)\")\n",
    "    print(\"   ‚úÖ Multi-day trend analysis (2day features)\")\n",
    "    \n",
    "    print(f\"\\nüí° EXPECTED MODEL IMPROVEMENTS:\")\n",
    "    print(\"   üöÄ Better trend continuation/reversal detection\")\n",
    "    print(\"   üìä Enhanced volume-price relationship modeling\")\n",
    "    print(\"   üéØ Improved intraday gap prediction\")\n",
    "    print(\"   üìà Better handling of market momentum\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Ready to retrain XGBoost model with enhanced features!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No features data available. Please run the feature engineering cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74530be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1900d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Missing libraries: No module named 'tensorflow'\n",
      "üì¶ Install with: pip install tensorflow\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Try to import RL libraries\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mtf\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, Model\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, LSTM, Dropout, Input\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# ü§ñ REINFORCEMENT LEARNING TRADING SYSTEM\n",
    "# Deep Q-Network (DQN) Agent for Bank Nifty Options Trading\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import RL libraries (lightweight version without TensorFlow)\n",
    "try:\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from collections import deque\n",
    "    import random\n",
    "    print(\"‚úÖ Scikit-learn and required libraries imported successfully\")\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Missing libraries: {e}\")\n",
    "    print(\"üì¶ Install with: pip install scikit-learn\")\n",
    "    raise\n",
    "\n",
    "# Try TensorFlow as optional (for advanced users)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "    print(\"‚úÖ TensorFlow also available for advanced RL\")\n",
    "except ImportError:\n",
    "    print(\"üí° TensorFlow not available - using lightweight sklearn implementation\")\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "\n",
    "print(\"ü§ñ REINFORCEMENT LEARNING BANK NIFTY TRADING SYSTEM\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "class BankNiftyTradingEnvironment:\n",
    "    \"\"\"\n",
    "    Trading environment for Bank Nifty options using engineered features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, features_df, initial_capital=100000, transaction_cost=0.001):\n",
    "        \"\"\"\n",
    "        Initialize trading environment\n",
    "        \n",
    "        Args:\n",
    "            features_df: DataFrame with engineered features\n",
    "            initial_capital: Starting capital in rupees\n",
    "            transaction_cost: Transaction cost as percentage (0.001 = 0.1%)\n",
    "        \"\"\"\n",
    "        self.features_df = features_df.copy()\n",
    "        self.initial_capital = initial_capital\n",
    "        self.transaction_cost = transaction_cost\n",
    "        \n",
    "        # Prepare features (exclude Date and target)\n",
    "        feature_cols = [col for col in features_df.columns if col not in ['Date', 'target_spot_price']]\n",
    "        self.features = features_df[feature_cols].fillna(0).values\n",
    "        self.prices = features_df['spot_price'].values\n",
    "        self.dates = features_df['Date'].values\n",
    "        \n",
    "        # Normalize features\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        self.scaler = StandardScaler()\n",
    "        self.features = self.scaler.fit_transform(self.features)\n",
    "        \n",
    "        # Environment state\n",
    "        self.reset()\n",
    "        \n",
    "        # Action space: 0=Hold, 1=Buy, 2=Sell\n",
    "        self.action_space = 3\n",
    "        self.state_size = self.features.shape[1] + 3  # features + position + capital + profit\n",
    "        \n",
    "        print(f\"üìä Environment initialized:\")\n",
    "        print(f\"   ‚Ä¢ Data points: {len(self.features)}\")\n",
    "        print(f\"   ‚Ä¢ Features: {self.features.shape[1]}\")\n",
    "        print(f\"   ‚Ä¢ State size: {self.state_size}\")\n",
    "        print(f\"   ‚Ä¢ Action space: {self.action_space}\")\n",
    "        print(f\"   ‚Ä¢ Initial capital: ‚Çπ{initial_capital:,.0f}\")\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset environment to initial state\"\"\"\n",
    "        self.current_step = 0\n",
    "        self.capital = self.initial_capital\n",
    "        self.position = 0  # 0=no position, 1=long, -1=short\n",
    "        self.entry_price = 0\n",
    "        self.total_profit = 0\n",
    "        self.trade_history = []\n",
    "        self.portfolio_values = [self.initial_capital]\n",
    "        \n",
    "        return self._get_state()\n",
    "    \n",
    "    def _get_state(self):\n",
    "        \"\"\"Get current state representation\"\"\"\n",
    "        if self.current_step >= len(self.features):\n",
    "            return np.zeros(self.state_size)\n",
    "        \n",
    "        # Market features\n",
    "        market_features = self.features[self.current_step]\n",
    "        \n",
    "        # Portfolio features\n",
    "        portfolio_features = np.array([\n",
    "            self.position,  # Current position\n",
    "            self.capital / self.initial_capital,  # Capital ratio\n",
    "            self.total_profit / self.initial_capital  # Profit ratio\n",
    "        ])\n",
    "        \n",
    "        return np.concatenate([market_features, portfolio_features])\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Execute action and return next state, reward, done flag\n",
    "        \n",
    "        Args:\n",
    "            action: 0=Hold, 1=Buy, 2=Sell\n",
    "            \n",
    "        Returns:\n",
    "            next_state, reward, done, info\n",
    "        \"\"\"\n",
    "        if self.current_step >= len(self.features) - 1:\n",
    "            return self._get_state(), 0, True, {}\n",
    "        \n",
    "        current_price = self.prices[self.current_step]\n",
    "        reward = 0\n",
    "        \n",
    "        # Execute action\n",
    "        if action == 1 and self.position == 0:  # Buy\n",
    "            self.position = 1\n",
    "            self.entry_price = current_price\n",
    "            transaction_cost = self.capital * self.transaction_cost\n",
    "            self.capital -= transaction_cost\n",
    "            \n",
    "        elif action == 2 and self.position == 1:  # Sell\n",
    "            profit = (current_price - self.entry_price) / self.entry_price\n",
    "            profit_amount = self.capital * profit\n",
    "            transaction_cost = self.capital * self.transaction_cost\n",
    "            \n",
    "            self.capital += profit_amount - transaction_cost\n",
    "            self.total_profit += profit_amount\n",
    "            \n",
    "            # Record trade\n",
    "            self.trade_history.append({\n",
    "                'entry_price': self.entry_price,\n",
    "                'exit_price': current_price,\n",
    "                'profit': profit_amount,\n",
    "                'date': self.dates[self.current_step]\n",
    "            })\n",
    "            \n",
    "            reward = profit * 100  # Scale reward\n",
    "            self.position = 0\n",
    "            self.entry_price = 0\n",
    "        \n",
    "        # Move to next step\n",
    "        self.current_step += 1\n",
    "        \n",
    "        # Calculate portfolio value\n",
    "        portfolio_value = self.capital\n",
    "        if self.position == 1:  # Add unrealized profit\n",
    "            unrealized = (self.prices[self.current_step] - self.entry_price) / self.entry_price * self.capital\n",
    "            portfolio_value += unrealized\n",
    "        \n",
    "        self.portfolio_values.append(portfolio_value)\n",
    "        \n",
    "        # Additional reward based on portfolio performance\n",
    "        if len(self.portfolio_values) > 1:\n",
    "            portfolio_return = (portfolio_value - self.portfolio_values[-2]) / self.portfolio_values[-2]\n",
    "            reward += portfolio_return * 10\n",
    "        \n",
    "        # Penalty for excessive trading\n",
    "        if action != 0:\n",
    "            reward -= 0.01\n",
    "        \n",
    "        # Check if done\n",
    "        done = self.current_step >= len(self.features) - 1\n",
    "        \n",
    "        info = {\n",
    "            'capital': self.capital,\n",
    "            'position': self.position,\n",
    "            'portfolio_value': portfolio_value,\n",
    "            'total_trades': len(self.trade_history)\n",
    "        }\n",
    "        \n",
    "        return self._get_state(), reward, done, info\n",
    "\n",
    "class SimpleDQNAgent:\n",
    "    \"\"\"\n",
    "    Lightweight DQN Agent using scikit-learn (no TensorFlow required)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, learning_rate=0.001):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = 0.95  # Discount factor\n",
    "        \n",
    "        # Build neural network using sklearn\n",
    "        self.q_network = MLPRegressor(\n",
    "            hidden_layer_sizes=(128, 64, 32),\n",
    "            activation='relu',\n",
    "            learning_rate_init=learning_rate,\n",
    "            max_iter=1,\n",
    "            warm_start=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Initialize network with dummy data\n",
    "        dummy_state = np.zeros((1, state_size))\n",
    "        dummy_target = np.zeros((1, action_size))\n",
    "        self.q_network.fit(dummy_state, dummy_target)\n",
    "        \n",
    "        print(f\"üß† Simple DQN Agent initialized:\")\n",
    "        print(f\"   ‚Ä¢ State size: {state_size}\")\n",
    "        print(f\"   ‚Ä¢ Action size: {action_size}\")\n",
    "        print(f\"   ‚Ä¢ Using sklearn MLPRegressor\")\n",
    "        print(f\"   ‚Ä¢ Memory size: 2000\")\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Store experience in memory\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        \"\"\"Choose action using epsilon-greedy policy\"\"\"\n",
    "        if np.random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        try:\n",
    "            q_values = self.q_network.predict(state.reshape(1, -1))\n",
    "            return np.argmax(q_values[0])\n",
    "        except:\n",
    "            return random.randrange(self.action_size)\n",
    "    \n",
    "    def replay(self, batch_size=32):\n",
    "        \"\"\"Train the model on a batch of experiences\"\"\"\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        \n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        states = np.array([e[0] for e in batch])\n",
    "        actions = np.array([e[1] for e in batch])\n",
    "        rewards = np.array([e[2] for e in batch])\n",
    "        next_states = np.array([e[3] for e in batch])\n",
    "        dones = np.array([e[4] for e in batch])\n",
    "        \n",
    "        try:\n",
    "            # Get Q-values for current states\n",
    "            current_q_values = self.q_network.predict(states)\n",
    "            \n",
    "            # Get Q-values for next states\n",
    "            next_q_values = self.q_network.predict(next_states)\n",
    "            \n",
    "            # Calculate target Q-values\n",
    "            target_q_values = current_q_values.copy()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                if dones[i]:\n",
    "                    target_q_values[i][actions[i]] = rewards[i]\n",
    "                else:\n",
    "                    target_q_values[i][actions[i]] = rewards[i] + self.gamma * np.max(next_q_values[i])\n",
    "            \n",
    "            # Train the model\n",
    "            self.q_network.fit(states, target_q_values)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Training error: {e}\")\n",
    "        \n",
    "        # Decay epsilon\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "class DQNAgent:\n",
    "    \"\"\"\n",
    "    Advanced DQN Agent using TensorFlow (optional - only if TensorFlow is available)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, learning_rate=0.001):\n",
    "        if not TENSORFLOW_AVAILABLE:\n",
    "            raise ImportError(\"TensorFlow not available. Use SimpleDQNAgent instead.\")\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = 0.95  # Discount factor\n",
    "        \n",
    "        # Build neural network\n",
    "        self.q_network = self._build_model()\n",
    "        self.target_network = self._build_model()\n",
    "        self.update_target_network()\n",
    "        \n",
    "        print(f\"üß† Advanced DQN Agent initialized:\")\n",
    "        print(f\"   ‚Ä¢ State size: {state_size}\")\n",
    "        print(f\"   ‚Ä¢ Action size: {action_size}\")\n",
    "        print(f\"   ‚Ä¢ Learning rate: {learning_rate}\")\n",
    "        print(f\"   ‚Ä¢ Memory size: 2000\")\n",
    "    \n",
    "    def _build_model(self):\n",
    "        \"\"\"Build neural network model\"\"\"\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, input_dim=self.state_size, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(self.action_size, activation='linear')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate), loss='mse')\n",
    "        return model\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        \"\"\"Update target network weights\"\"\"\n",
    "        self.target_network.set_weights(self.q_network.get_weights())\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Store experience in memory\"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        \"\"\"Choose action using epsilon-greedy policy\"\"\"\n",
    "        if np.random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        q_values = self.q_network.predict(state.reshape(1, -1), verbose=0)\n",
    "        return np.argmax(q_values[0])\n",
    "    \n",
    "    def replay(self, batch_size=32):\n",
    "        \"\"\"Train the model on a batch of experiences\"\"\"\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        \n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        states = np.array([e[0] for e in batch])\n",
    "        actions = np.array([e[1] for e in batch])\n",
    "        rewards = np.array([e[2] for e in batch])\n",
    "        next_states = np.array([e[3] for e in batch])\n",
    "        dones = np.array([e[4] for e in batch])\n",
    "        \n",
    "        # Get Q-values for current states\n",
    "        current_q_values = self.q_network.predict(states, verbose=0)\n",
    "        \n",
    "        # Get Q-values for next states from target network\n",
    "        next_q_values = self.target_network.predict(next_states, verbose=0)\n",
    "        \n",
    "        # Calculate target Q-values\n",
    "        target_q_values = current_q_values.copy()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            if dones[i]:\n",
    "                target_q_values[i][actions[i]] = rewards[i]\n",
    "            else:\n",
    "                target_q_values[i][actions[i]] = rewards[i] + self.gamma * np.max(next_q_values[i])\n",
    "        \n",
    "        # Train the model\n",
    "        self.q_network.fit(states, target_q_values, epochs=1, verbose=0)\n",
    "        \n",
    "        # Decay epsilon\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "def train_rl_agent(features_df, episodes=100, initial_capital=100000):\n",
    "    \"\"\"\n",
    "    Train reinforcement learning agent\n",
    "    \n",
    "    Args:\n",
    "        features_df: DataFrame with engineered features\n",
    "        episodes: Number of training episodes\n",
    "        initial_capital: Starting capital\n",
    "    \n",
    "    Returns:\n",
    "        trained_agent, environment, training_results\n",
    "    \"\"\"\n",
    "    print(f\"\\nüöÄ TRAINING RL AGENT\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Create environment and agent\n",
    "    env = BankNiftyTradingEnvironment(features_df, initial_capital)\n",
    "    agent = DQNAgent(env.state_size, env.action_space)\n",
    "    \n",
    "    # Training metrics\n",
    "    episode_rewards = []\n",
    "    episode_profits = []\n",
    "    episode_trades = []\n",
    "    \n",
    "    print(f\"\\nüìä Starting training for {episodes} episodes...\")\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        \n",
    "        while True:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        # Train agent\n",
    "        if len(agent.memory) > 32:\n",
    "            agent.replay()\n",
    "        \n",
    "        # Update target network every 10 episodes\n",
    "        if episode % 10 == 0:\n",
    "            agent.update_target_network()\n",
    "        \n",
    "        # Record metrics\n",
    "        final_portfolio = env.portfolio_values[-1]\n",
    "        profit = final_portfolio - initial_capital\n",
    "        profit_pct = (profit / initial_capital) * 100\n",
    "        \n",
    "        episode_rewards.append(total_reward)\n",
    "        episode_profits.append(profit_pct)\n",
    "        episode_trades.append(len(env.trade_history))\n",
    "        \n",
    "        # Print progress\n",
    "        if episode % 20 == 0:\n",
    "            avg_reward = np.mean(episode_rewards[-20:]) if len(episode_rewards) >= 20 else np.mean(episode_rewards)\n",
    "            avg_profit = np.mean(episode_profits[-20:]) if len(episode_profits) >= 20 else np.mean(episode_profits)\n",
    "            \n",
    "            print(f\"Episode {episode:3d} | Reward: {total_reward:8.2f} | \"\n",
    "                  f\"Profit: {profit_pct:6.2f}% | Trades: {len(env.trade_history):3d} | \"\n",
    "                  f\"Epsilon: {agent.epsilon:.3f}\")\n",
    "    \n",
    "    training_results = {\n",
    "        'episode_rewards': episode_rewards,\n",
    "        'episode_profits': episode_profits,\n",
    "        'episode_trades': episode_trades,\n",
    "        'final_epsilon': agent.epsilon\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training completed!\")\n",
    "    print(f\"   ‚Ä¢ Final epsilon: {agent.epsilon:.3f}\")\n",
    "    print(f\"   ‚Ä¢ Average profit (last 20): {np.mean(episode_profits[-20:]):.2f}%\")\n",
    "    print(f\"   ‚Ä¢ Average trades (last 20): {np.mean(episode_trades[-20:]):.1f}\")\n",
    "    \n",
    "    return agent, env, training_results\n",
    "\n",
    "def test_rl_agent(agent, features_df, initial_capital=100000):\n",
    "    \"\"\"\n",
    "    Test trained RL agent\n",
    "    \n",
    "    Args:\n",
    "        agent: Trained DQN agent\n",
    "        features_df: Test data\n",
    "        initial_capital: Starting capital\n",
    "    \n",
    "    Returns:\n",
    "        test_results\n",
    "    \"\"\"\n",
    "    print(f\"\\nüß™ TESTING RL AGENT\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Create test environment\n",
    "    env = BankNiftyTradingEnvironment(features_df, initial_capital)\n",
    "    \n",
    "    # Test with no exploration\n",
    "    agent.epsilon = 0\n",
    "    \n",
    "    state = env.reset()\n",
    "    actions_taken = []\n",
    "    states_history = []\n",
    "    \n",
    "    while True:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        actions_taken.append(action)\n",
    "        states_history.append(info)\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    final_portfolio = env.portfolio_values[-1]\n",
    "    total_return = (final_portfolio - initial_capital) / initial_capital * 100\n",
    "    \n",
    "    # Calculate benchmark (buy and hold)\n",
    "    benchmark_return = (env.prices[-1] - env.prices[0]) / env.prices[0] * 100\n",
    "    \n",
    "    # Calculate Sharpe ratio (simplified)\n",
    "    returns = np.diff(env.portfolio_values) / env.portfolio_values[:-1]\n",
    "    sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(252) if np.std(returns) > 0 else 0\n",
    "    \n",
    "    # Calculate maximum drawdown\n",
    "    peak = np.maximum.accumulate(env.portfolio_values)\n",
    "    drawdown = (env.portfolio_values - peak) / peak\n",
    "    max_drawdown = np.min(drawdown) * 100\n",
    "    \n",
    "    test_results = {\n",
    "        'total_return': total_return,\n",
    "        'benchmark_return': benchmark_return,\n",
    "        'excess_return': total_return - benchmark_return,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'total_trades': len(env.trade_history),\n",
    "        'win_rate': len([t for t in env.trade_history if t['profit'] > 0]) / max(len(env.trade_history), 1) * 100,\n",
    "        'portfolio_values': env.portfolio_values,\n",
    "        'trade_history': env.trade_history,\n",
    "        'actions_taken': actions_taken,\n",
    "        'dates': env.dates\n",
    "    }\n",
    "    \n",
    "    print(f\"üìä TEST RESULTS:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"   üí∞ Total Return: {total_return:.2f}%\")\n",
    "    print(f\"   üìà Benchmark Return: {benchmark_return:.2f}%\")\n",
    "    print(f\"   ‚ö° Excess Return: {test_results['excess_return']:.2f}%\")\n",
    "    print(f\"   üìä Sharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "    print(f\"   üìâ Max Drawdown: {max_drawdown:.2f}%\")\n",
    "    print(f\"   üîÑ Total Trades: {len(env.trade_history)}\")\n",
    "    print(f\"   üéØ Win Rate: {test_results['win_rate']:.1f}%\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# Main execution\n",
    "if 'features_df' in locals() and not features_df.empty:\n",
    "    print(\"‚úÖ Features data found - Starting RL training...\")\n",
    "    \n",
    "    # Split data for training and testing\n",
    "    train_size = int(0.8 * len(features_df))\n",
    "    train_data = features_df.iloc[:train_size].copy()\n",
    "    test_data = features_df.iloc[train_size:].copy()\n",
    "    \n",
    "    print(f\"\\nüìä DATA SPLIT:\")\n",
    "    print(f\"   ‚Ä¢ Training: {len(train_data)} samples\")\n",
    "    print(f\"   ‚Ä¢ Testing: {len(test_data)} samples\")\n",
    "    \n",
    "    # Train the agent\n",
    "    trained_agent, train_env, training_results = train_rl_agent(\n",
    "        train_data, \n",
    "        episodes=200,  # Increase for better performance\n",
    "        initial_capital=100000\n",
    "    )\n",
    "    \n",
    "    # Test the agent\n",
    "    test_results = test_rl_agent(trained_agent, test_data)\n",
    "    \n",
    "    # Store results for later use\n",
    "    rl_results = {\n",
    "        'agent': trained_agent,\n",
    "        'training_results': training_results,\n",
    "        'test_results': test_results,\n",
    "        'train_data': train_data,\n",
    "        'test_data': test_data\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüéØ RL SYSTEM READY!\")\n",
    "    print(\"üíæ Results stored in 'rl_results' variable\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No features data available.\")\n",
    "    print(\"üí° Please run the feature engineering cell first.\")\n",
    "\n",
    "print(f\"\\nüîÑ NEXT STEPS:\")\n",
    "print(\"‚Ä¢ Visualize training progress\")\n",
    "print(\"‚Ä¢ Analyze trading performance\") \n",
    "print(\"‚Ä¢ Compare with benchmark\")\n",
    "print(\"‚Ä¢ Deploy for live trading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà RL TRADING RESULTS VISUALIZATION & ANALYSIS\n",
    "# Comprehensive analysis of reinforcement learning trading performance\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"üìà RL TRADING PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "if 'rl_results' in locals():\n",
    "    training_results = rl_results['training_results']\n",
    "    test_results = rl_results['test_results']\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Training Progress: Episode Rewards',\n",
    "            'Training Progress: Episode Profits (%)',\n",
    "            'Portfolio Value vs Benchmark',\n",
    "            'Cumulative Returns Comparison',\n",
    "            'Trade Distribution',\n",
    "            'Monthly Returns Heatmap'\n",
    "        ],\n",
    "        specs=[\n",
    "            [{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "            [{\"secondary_y\": True}, {\"secondary_y\": False}],\n",
    "            [{\"secondary_y\": False}, {\"secondary_y\": False}]\n",
    "        ],\n",
    "        vertical_spacing=0.08,\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    # 1. Training Progress - Rewards\n",
    "    episodes = list(range(len(training_results['episode_rewards'])))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=episodes,\n",
    "            y=training_results['episode_rewards'],\n",
    "            mode='lines',\n",
    "            name='Episode Rewards',\n",
    "            line=dict(color='blue', width=1),\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Add moving average\n",
    "    window = 20\n",
    "    if len(training_results['episode_rewards']) >= window:\n",
    "        moving_avg = pd.Series(training_results['episode_rewards']).rolling(window).mean()\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=episodes,\n",
    "                y=moving_avg,\n",
    "                mode='lines',\n",
    "                name=f'{window}-Episode MA',\n",
    "                line=dict(color='red', width=2)\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. Training Progress - Profits\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=episodes,\n",
    "            y=training_results['episode_profits'],\n",
    "            mode='lines',\n",
    "            name='Episode Profits (%)',\n",
    "            line=dict(color='green', width=1),\n",
    "            opacity=0.7\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    if len(training_results['episode_profits']) >= window:\n",
    "        profit_ma = pd.Series(training_results['episode_profits']).rolling(window).mean()\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=episodes,\n",
    "                y=profit_ma,\n",
    "                mode='lines',\n",
    "                name=f'{window}-Episode Profit MA',\n",
    "                line=dict(color='darkgreen', width=2)\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    \n",
    "    # 3. Portfolio Value vs Benchmark\n",
    "    test_dates = test_results['dates'][:len(test_results['portfolio_values'])]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=test_dates,\n",
    "            y=test_results['portfolio_values'],\n",
    "            mode='lines',\n",
    "            name='RL Agent Portfolio',\n",
    "            line=dict(color='blue', width=2)\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Calculate benchmark portfolio\n",
    "    if 'test_data' in rl_results:\n",
    "        test_data = rl_results['test_data']\n",
    "        initial_price = test_data['spot_price'].iloc[0]\n",
    "        benchmark_portfolio = [100000 * (price / initial_price) for price in test_data['spot_price'][:len(test_results['portfolio_values'])]]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=test_dates,\n",
    "                y=benchmark_portfolio,\n",
    "                mode='lines',\n",
    "                name='Buy & Hold Benchmark',\n",
    "                line=dict(color='red', width=2, dash='dash')\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # 4. Cumulative Returns\n",
    "    rl_returns = [(val / 100000 - 1) * 100 for val in test_results['portfolio_values']]\n",
    "    benchmark_returns = [(val / 100000 - 1) * 100 for val in benchmark_portfolio] if 'benchmark_portfolio' in locals() else [0] * len(rl_returns)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=test_dates,\n",
    "            y=rl_returns,\n",
    "            mode='lines',\n",
    "            name='RL Cumulative Return (%)',\n",
    "            line=dict(color='blue', width=2)\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=test_dates,\n",
    "            y=benchmark_returns,\n",
    "            mode='lines',\n",
    "            name='Benchmark Return (%)',\n",
    "            line=dict(color='red', width=2, dash='dash')\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # 5. Trade Distribution\n",
    "    if test_results['trade_history']:\n",
    "        trade_profits = [trade['profit'] for trade in test_results['trade_history']]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=trade_profits,\n",
    "                nbinsx=20,\n",
    "                name='Trade P&L Distribution',\n",
    "                marker=dict(color='lightblue', line=dict(color='blue', width=1))\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "    \n",
    "    # 6. Action Distribution Pie Chart\n",
    "    action_counts = pd.Series(test_results['actions_taken']).value_counts()\n",
    "    action_labels = ['Hold', 'Buy', 'Sell']\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=[action_labels[i] for i in action_counts.index],\n",
    "            values=action_counts.values,\n",
    "            name=\"Action Distribution\",\n",
    "            marker=dict(colors=['lightgray', 'lightgreen', 'lightcoral'])\n",
    "        ),\n",
    "        row=3, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'RL Trading System Analysis<br><sub>Total Return: {test_results[\"total_return\"]:.2f}% | Excess Return: {test_results[\"excess_return\"]:.2f}% | Sharpe: {test_results[\"sharpe_ratio\"]:.3f}</sub>',\n",
    "        height=1200,\n",
    "        showlegend=True,\n",
    "        font=dict(size=10)\n",
    "    )\n",
    "    \n",
    "    # Update axis labels\n",
    "    fig.update_xaxes(title_text=\"Episode\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Reward\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Episode\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Profit (%)\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Portfolio Value (‚Çπ)\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Cumulative Return (%)\", row=2, col=2)\n",
    "    fig.update_xaxes(title_text=\"Trade P&L (‚Çπ)\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=3, col=1)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Performance Summary Table\n",
    "    print(f\"\\nüìä DETAILED PERFORMANCE METRICS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    performance_data = {\n",
    "        'Metric': [\n",
    "            'Total Return (%)',\n",
    "            'Benchmark Return (%)', \n",
    "            'Excess Return (%)',\n",
    "            'Sharpe Ratio',\n",
    "            'Maximum Drawdown (%)',\n",
    "            'Total Trades',\n",
    "            'Win Rate (%)',\n",
    "            'Average Trade P&L (‚Çπ)',\n",
    "            'Best Trade (‚Çπ)',\n",
    "            'Worst Trade (‚Çπ)',\n",
    "            'Final Portfolio Value (‚Çπ)'\n",
    "        ],\n",
    "        'Value': [\n",
    "            f\"{test_results['total_return']:.2f}\",\n",
    "            f\"{test_results['benchmark_return']:.2f}\",\n",
    "            f\"{test_results['excess_return']:.2f}\",\n",
    "            f\"{test_results['sharpe_ratio']:.3f}\",\n",
    "            f\"{test_results['max_drawdown']:.2f}\",\n",
    "            f\"{test_results['total_trades']}\",\n",
    "            f\"{test_results['win_rate']:.1f}\",\n",
    "            f\"‚Çπ{np.mean([t['profit'] for t in test_results['trade_history']]) if test_results['trade_history'] else 0:,.0f}\",\n",
    "            f\"‚Çπ{max([t['profit'] for t in test_results['trade_history']]) if test_results['trade_history'] else 0:,.0f}\",\n",
    "            f\"‚Çπ{min([t['profit'] for t in test_results['trade_history']]) if test_results['trade_history'] else 0:,.0f}\",\n",
    "            f\"‚Çπ{test_results['portfolio_values'][-1]:,.0f}\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    performance_df = pd.DataFrame(performance_data)\n",
    "    print(performance_df.to_string(index=False))\n",
    "    \n",
    "    # Trading Analysis\n",
    "    print(f\"\\nüîç TRADING BEHAVIOR ANALYSIS\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    action_dist = pd.Series(test_results['actions_taken']).value_counts()\n",
    "    total_actions = len(test_results['actions_taken'])\n",
    "    \n",
    "    print(f\"üìä Action Distribution:\")\n",
    "    print(f\"   ‚Ä¢ Hold: {action_dist.get(0, 0)} ({action_dist.get(0, 0)/total_actions*100:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Buy:  {action_dist.get(1, 0)} ({action_dist.get(1, 0)/total_actions*100:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Sell: {action_dist.get(2, 0)} ({action_dist.get(2, 0)/total_actions*100:.1f}%)\")\n",
    "    \n",
    "    if test_results['trade_history']:\n",
    "        winning_trades = [t for t in test_results['trade_history'] if t['profit'] > 0]\n",
    "        losing_trades = [t for t in test_results['trade_history'] if t['profit'] <= 0]\n",
    "        \n",
    "        print(f\"\\nüí∞ Trade Statistics:\")\n",
    "        print(f\"   ‚Ä¢ Winning Trades: {len(winning_trades)}\")\n",
    "        print(f\"   ‚Ä¢ Losing Trades: {len(losing_trades)}\")\n",
    "        \n",
    "        if winning_trades:\n",
    "            avg_win = np.mean([t['profit'] for t in winning_trades])\n",
    "            print(f\"   ‚Ä¢ Average Win: ‚Çπ{avg_win:,.0f}\")\n",
    "        \n",
    "        if losing_trades:\n",
    "            avg_loss = np.mean([t['profit'] for t in losing_trades])\n",
    "            print(f\"   ‚Ä¢ Average Loss: ‚Çπ{avg_loss:,.0f}\")\n",
    "        \n",
    "        if winning_trades and losing_trades:\n",
    "            profit_factor = abs(sum([t['profit'] for t in winning_trades]) / sum([t['profit'] for t in losing_trades]))\n",
    "            print(f\"   ‚Ä¢ Profit Factor: {profit_factor:.2f}\")\n",
    "    \n",
    "    # Model Confidence Analysis\n",
    "    print(f\"\\nüß† MODEL LEARNING ANALYSIS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    final_episodes = training_results['episode_profits'][-20:]\n",
    "    print(f\"   ‚Ä¢ Final 20 episodes avg profit: {np.mean(final_episodes):.2f}%\")\n",
    "    print(f\"   ‚Ä¢ Final epsilon (exploration): {training_results['final_epsilon']:.3f}\")\n",
    "    print(f\"   ‚Ä¢ Learning stability: {'Good' if np.std(final_episodes) < 5 else 'Needs more training'}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nüí° RECOMMENDATIONS\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    if test_results['excess_return'] > 0:\n",
    "        print(\"   ‚úÖ RL agent outperforms benchmark\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è RL agent underperforms benchmark\")\n",
    "    \n",
    "    if test_results['sharpe_ratio'] > 1:\n",
    "        print(\"   ‚úÖ Good risk-adjusted returns\")\n",
    "    elif test_results['sharpe_ratio'] > 0.5:\n",
    "        print(\"   üìä Moderate risk-adjusted returns\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Poor risk-adjusted returns\")\n",
    "    \n",
    "    if test_results['max_drawdown'] < -10:\n",
    "        print(\"   ‚ö†Ô∏è High drawdown - consider position sizing\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Acceptable drawdown levels\")\n",
    "    \n",
    "    print(f\"\\nüéØ NEXT STEPS:\")\n",
    "    print(\"   ‚Ä¢ Fine-tune hyperparameters\")\n",
    "    print(\"   ‚Ä¢ Increase training episodes\") \n",
    "    print(\"   ‚Ä¢ Add more sophisticated features\")\n",
    "    print(\"   ‚Ä¢ Implement risk management rules\")\n",
    "    print(\"   ‚Ä¢ Test on different market conditions\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No RL results available.\")\n",
    "    print(\"üí° Please run the RL training cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a8e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéõÔ∏è INTERACTIVE BANK NIFTY PREDICTION WIDGET\n",
      "==================================================\n",
      "üìÇ Project root: c:\\Users\\91894\\Projects\\market-data\n",
      "üîß Source path: c:\\Users\\91894\\Projects\\market-data\\src\n",
      "‚úÖ Successfully imported prediction_widget\n",
      "\n",
      "üéØ LOADING INTERACTIVE PREDICTION INTERFACE\n",
      "---------------------------------------------\n",
      "‚úÖ XGBoost model found - Creating interactive widget...\n",
      "üéõÔ∏è INTERACTIVE BANK NIFTY PREDICTION WIDGET\n",
      "==================================================\n",
      "üéØ Creating Interactive Prediction Interface...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3153aa9337f64a8e8d56f8b9d87a3297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>üéõÔ∏è Interactive Bank Nifty Prediction Widget</h2>'), HBox(children=(VBox(childre‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Interactive prediction widget loaded successfully!\n",
      "üéØ Use the interface above to make predictions\n",
      "\n",
      "üéõÔ∏è WIDGET FEATURES:\n",
      "--------------------\n",
      "‚Ä¢ üí∞ Market data input fields\n",
      "‚Ä¢ üìã Quick preset scenarios (Bullish/Bearish/Neutral)\n",
      "‚Ä¢ üîÆ One-click prediction button\n",
      "‚Ä¢ üìä Real-time results with market signals\n",
      "‚Ä¢ üéØ Confidence indicators and trading insights\n",
      "\n",
      "üí° Use the interface above to make predictions!\n",
      "\n",
      "üéØ USAGE INSTRUCTIONS\n",
      "--------------------\n",
      "1. üöÄ Train the XGBoost model first (run previous cells)\n",
      "2. üîÑ Re-run this cell to load the widget\n",
      "3. üéõÔ∏è Use the interactive interface above\n",
      "4. üîÆ Click 'Make Prediction' for instant results\n",
      "\n",
      "üí° FALLBACK OPTIONS:\n",
      "‚Ä¢ display_prediction_widget(model_results) - Main widget\n",
      "‚Ä¢ create_simple_prediction_form(model_results) - Text form\n",
      "\n",
      "‚úÖ Prediction widget utilities loaded from utils module!\n"
     ]
    }
   ],
   "source": [
    "# üéõÔ∏è INTERACTIVE MANUAL PREDICTION WIDGET\n",
    "# Widget-based interface for easy manual predictions using utils module\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"üéõÔ∏è INTERACTIVE BANK NIFTY PREDICTION WIDGET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Setup path to import custom modules\n",
    "current_dir = os.getcwd()\n",
    "if 'notebooks' in current_dir:\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(f\"üìÇ Project root: {project_root}\")\n",
    "print(f\"üîß Source path: {src_path}\")\n",
    "\n",
    "# Import the prediction widget from utils\n",
    "try:\n",
    "    from utils.prediction_widget import display_prediction_widget, create_simple_prediction_form\n",
    "    print(\"‚úÖ Successfully imported prediction_widget\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import prediction_widget: {e}\")\n",
    "    print(\"üí° Make sure the src/utils/prediction_widget.py file exists\")\n",
    "    raise\n",
    "\n",
    "# Display the interactive widget (if model is available)\n",
    "print(\"\\nüéØ LOADING INTERACTIVE PREDICTION INTERFACE\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "if 'model_results' in globals():\n",
    "    print(\"‚úÖ XGBoost model found - Creating interactive widget...\")\n",
    "    \n",
    "    # Create and display the widget using the utils function\n",
    "    try:\n",
    "        widget = display_prediction_widget(model_results)\n",
    "        if widget:\n",
    "            print(\"\\nüéõÔ∏è WIDGET FEATURES:\")\n",
    "            print(\"-\" * 20)\n",
    "            print(\"‚Ä¢ üí∞ Market data input fields\")\n",
    "            print(\"‚Ä¢ üìã Quick preset scenarios (Bullish/Bearish/Neutral)\")\n",
    "            print(\"‚Ä¢ üîÆ One-click prediction button\")\n",
    "            print(\"‚Ä¢ üìä Real-time results with market signals\")\n",
    "            print(\"‚Ä¢ üéØ Confidence indicators and trading insights\")\n",
    "            print(\"\\nüí° Use the interface above to make predictions!\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Widget creation failed\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating widget: {str(e)}\")\n",
    "        print(\"üí° Falling back to simple form interface...\")\n",
    "        \n",
    "        # Fallback to simple form\n",
    "        try:\n",
    "            simple_form = create_simple_prediction_form(model_results)\n",
    "            print(\"‚úÖ Simple prediction form available\")\n",
    "            print(\"üí° Call simple_form() to use text-based interface\")\n",
    "        except:\n",
    "            print(\"‚ùå Both widget and form creation failed\")\n",
    "            \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è XGBoost model not available yet\")\n",
    "    print(\"üí° Please run the XGBoost training cells first\")\n",
    "    print(\"üîß Then run this cell again to load the widget\")\n",
    "    \n",
    "    # Show preview of what will be available\n",
    "    print(f\"\\nüìã WIDGET PREVIEW (Available after model training):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"üéõÔ∏è Interactive controls for:\")\n",
    "    print(\"‚Ä¢ üí∞ Current Bank Nifty spot price\")\n",
    "    print(\"‚Ä¢ üìà Call options (Volume, OI, LTP, ATM)\")\n",
    "    print(\"‚Ä¢ üìâ Put options (Volume, OI, LTP, ATM)\")\n",
    "    print(\"‚Ä¢ üîÆ Instant prediction button\")\n",
    "    print(\"‚Ä¢ üìã Preset scenarios for quick testing\")\n",
    "\n",
    "print(f\"\\nüéØ USAGE INSTRUCTIONS\")\n",
    "print(\"-\" * 20)\n",
    "print(\"1. üöÄ Train the XGBoost model first (run previous cells)\")\n",
    "print(\"2. üîÑ Re-run this cell to load the widget\")\n",
    "print(\"3. üéõÔ∏è Use the interactive interface above\")\n",
    "print(\"4. üîÆ Click 'Make Prediction' for instant results\")\n",
    "\n",
    "print(f\"\\nüí° FALLBACK OPTIONS:\")\n",
    "print(\"‚Ä¢ display_prediction_widget(model_results) - Main widget\")\n",
    "print(\"‚Ä¢ create_simple_prediction_form(model_results) - Text form\")\n",
    "\n",
    "print(f\"\\n‚úÖ Prediction widget utilities loaded from utils module!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822437e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank Nifty Option Chain (Zerodha Kite):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tradingsymbol</th>\n",
       "      <th>strike</th>\n",
       "      <th>expiry</th>\n",
       "      <th>instrument_type</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>tick_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BANKNIFTY25JUL56500CE</td>\n",
       "      <td>56500.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>CE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BANKNIFTY25JUL56500PE</td>\n",
       "      <td>56500.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>PE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANKNIFTY25JUL56600CE</td>\n",
       "      <td>56600.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>CE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANKNIFTY25JUL56600PE</td>\n",
       "      <td>56600.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>PE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANKNIFTY25JUL56400CE</td>\n",
       "      <td>56400.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>CE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BANKNIFTY25JUL56400PE</td>\n",
       "      <td>56400.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>PE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BANKNIFTY25JUL56700CE</td>\n",
       "      <td>56700.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>CE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BANKNIFTY25JUL56700PE</td>\n",
       "      <td>56700.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>PE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BANKNIFTY25JUL56300CE</td>\n",
       "      <td>56300.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>CE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BANKNIFTY25JUL56300PE</td>\n",
       "      <td>56300.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>PE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BANKNIFTY25JUL56800CE</td>\n",
       "      <td>56800.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>CE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BANKNIFTY25JUL56800PE</td>\n",
       "      <td>56800.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>PE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BANKNIFTY25JUL56200CE</td>\n",
       "      <td>56200.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>CE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BANKNIFTY25JUL56200PE</td>\n",
       "      <td>56200.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>PE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BANKNIFTY25JUL56900CE</td>\n",
       "      <td>56900.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>CE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BANKNIFTY25JUL56900PE</td>\n",
       "      <td>56900.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>PE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BANKNIFTY25JUL56100CE</td>\n",
       "      <td>56100.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>CE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BANKNIFTY25JUL56100PE</td>\n",
       "      <td>56100.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>PE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BANKNIFTY25JUL57000CE</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>CE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BANKNIFTY25JUL57000PE</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>PE</td>\n",
       "      <td>35</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tradingsymbol   strike      expiry instrument_type  lot_size  \\\n",
       "0   BANKNIFTY25JUL56500CE  56500.0  2025-07-31              CE        35   \n",
       "1   BANKNIFTY25JUL56500PE  56500.0  2025-07-31              PE        35   \n",
       "2   BANKNIFTY25JUL56600CE  56600.0  2025-07-31              CE        35   \n",
       "3   BANKNIFTY25JUL56600PE  56600.0  2025-07-31              PE        35   \n",
       "4   BANKNIFTY25JUL56400CE  56400.0  2025-07-31              CE        35   \n",
       "5   BANKNIFTY25JUL56400PE  56400.0  2025-07-31              PE        35   \n",
       "6   BANKNIFTY25JUL56700CE  56700.0  2025-07-31              CE        35   \n",
       "7   BANKNIFTY25JUL56700PE  56700.0  2025-07-31              PE        35   \n",
       "8   BANKNIFTY25JUL56300CE  56300.0  2025-07-31              CE        35   \n",
       "9   BANKNIFTY25JUL56300PE  56300.0  2025-07-31              PE        35   \n",
       "10  BANKNIFTY25JUL56800CE  56800.0  2025-07-31              CE        35   \n",
       "11  BANKNIFTY25JUL56800PE  56800.0  2025-07-31              PE        35   \n",
       "12  BANKNIFTY25JUL56200CE  56200.0  2025-07-31              CE        35   \n",
       "13  BANKNIFTY25JUL56200PE  56200.0  2025-07-31              PE        35   \n",
       "14  BANKNIFTY25JUL56900CE  56900.0  2025-07-31              CE        35   \n",
       "15  BANKNIFTY25JUL56900PE  56900.0  2025-07-31              PE        35   \n",
       "16  BANKNIFTY25JUL56100CE  56100.0  2025-07-31              CE        35   \n",
       "17  BANKNIFTY25JUL56100PE  56100.0  2025-07-31              PE        35   \n",
       "18  BANKNIFTY25JUL57000CE  57000.0  2025-07-31              CE        35   \n",
       "19  BANKNIFTY25JUL57000PE  57000.0  2025-07-31              PE        35   \n",
       "\n",
       "    tick_size  \n",
       "0        0.05  \n",
       "1        0.05  \n",
       "2        0.05  \n",
       "3        0.05  \n",
       "4        0.05  \n",
       "5        0.05  \n",
       "6        0.05  \n",
       "7        0.05  \n",
       "8        0.05  \n",
       "9        0.05  \n",
       "10       0.05  \n",
       "11       0.05  \n",
       "12       0.05  \n",
       "13       0.05  \n",
       "14       0.05  \n",
       "15       0.05  \n",
       "16       0.05  \n",
       "17       0.05  \n",
       "18       0.05  \n",
       "19       0.05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install kiteconnect\n",
    "from kiteconnect import KiteConnect\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load API key and access token from environment variables for security\n",
    "api_key = \"v2qa0jwrkw1l7489\"\n",
    "access_token = \"17b9qraamiojz39sj7xa0hkaoqctf7fu\"\n",
    "\n",
    "kite = KiteConnect(api_key=api_key)\n",
    "kite.set_access_token(access_token)\n",
    "\n",
    "# Example: Fetch option chain for Bank Nifty (replace with your instrument_token if needed)\n",
    "# Get instruments list and filter for Bank Nifty options\n",
    "instruments = kite.instruments(exchange=\"NFO\")\n",
    "banknifty_options = [inst for inst in instruments if inst['name'] == 'BANKNIFTY' and inst['segment'] == 'NFO-OPT']\n",
    "\n",
    "# Create DataFrame for tabular display\n",
    "option_chain_df = pd.DataFrame(banknifty_options)\n",
    "\n",
    "# Display relevant columns\n",
    "display_columns = ['tradingsymbol', 'strike', 'expiry', 'instrument_type', 'lot_size', 'tick_size']\n",
    "print(\"Bank Nifty Option Chain (Zerodha Kite):\")\n",
    "display(option_chain_df[display_columns].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb2c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ REAL-TIME BANK NIFTY PREDICTION ENGINE\n",
      "==================================================\n",
      "\n",
      "üéõÔ∏è INTERACTIVE PREDICTION INTERFACE\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313ff19bf3a7430ea2bed653faffdc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>üöÄ Real-Time Prediction Controls</h3>'), HBox(children=(Button(bu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Interactive interface loaded successfully!\n",
      "üí° Use the buttons above to start predictions\n",
      "\n",
      "üöÄ RUNNING INITIAL PREDICTION...\n",
      "üïê 14:00:34 - Starting live prediction cycle...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "make_live_prediction() got an unexpected keyword argument 'use_previous_day_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 305\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mmodel_results\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mand\u001b[39;00m kite \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    304\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müöÄ RUNNING INITIAL PREDICTION...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m     initial_result = \u001b[43mrun_live_prediction_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m initial_result:\n\u001b[32m    308\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Initial prediction completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mrun_live_prediction_cycle\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Make live prediction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m result = \u001b[43mmake_live_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_previous_day_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result[\u001b[33m'\u001b[39m\u001b[33msuccess\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     26\u001b[39m     current_spot = result[\u001b[33m'\u001b[39m\u001b[33mcurrent_spot\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mTypeError\u001b[39m: make_live_prediction() got an unexpected keyword argument 'use_previous_day_data'"
     ]
    }
   ],
   "source": [
    "# üöÄ REAL-TIME PREDICTION ENGINE WITH KITECONNECT\n",
    "# Complete real-time prediction system using live market data\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"üöÄ REAL-TIME BANK NIFTY PREDICTION ENGINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def run_live_prediction_cycle():\n",
    "    \"\"\"Run a single live prediction cycle\"\"\"\n",
    "    \n",
    "    if 'model_results' not in globals():\n",
    "        print(\"‚ùå XGBoost model not available. Please run the training cells first.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üïê {datetime.now().strftime('%H:%M:%S')} - Starting live prediction cycle...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Make live prediction\n",
    "    result = make_live_prediction(use_previous_day_data=True)\n",
    "    \n",
    "    if result['success']:\n",
    "        current_spot = result['current_spot']\n",
    "        predicted_spot = result['predicted_spot']\n",
    "        difference = result['difference']\n",
    "        difference_pct = result['difference_pct']\n",
    "        features = result['features_used']\n",
    "        \n",
    "        print(f\"üìä LIVE PREDICTION RESULTS\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"üí∞ Current Spot Price: ‚Çπ{current_spot:,.2f}\")\n",
    "        print(f\"üîÆ Predicted Price:    ‚Çπ{predicted_spot:,.2f}\")\n",
    "        print(f\"üìà Difference:         ‚Çπ{difference:+,.2f} ({difference_pct:+.2f}%)\")\n",
    "        \n",
    "        # Market direction indicator\n",
    "        if difference > 0:\n",
    "            direction = \"üìà BULLISH\"\n",
    "            color = \"üü¢\"\n",
    "        elif difference < 0:\n",
    "            direction = \"üìâ BEARISH\" \n",
    "            color = \"üî¥\"\n",
    "        else:\n",
    "            direction = \"‚öñÔ∏è NEUTRAL\"\n",
    "            color = \"üü°\"\n",
    "        \n",
    "        print(f\"üéØ Market Direction:   {color} {direction}\")\n",
    "        \n",
    "        # Confidence indicator based on prediction magnitude\n",
    "        confidence_pct = min(abs(difference_pct) * 10, 100)  # Scale confidence\n",
    "        confidence_bars = \"‚ñà\" * int(confidence_pct / 10)\n",
    "        print(f\"üìä Confidence:        {confidence_bars} {confidence_pct:.0f}%\")\n",
    "        \n",
    "        # Key market indicators\n",
    "        print(f\"\\nüìã KEY MARKET INDICATORS\")\n",
    "        print(\"-\" * 25)\n",
    "        \n",
    "        # Put-Call Ratio\n",
    "        pcr_volume = features.get('pcr_volume', 0)\n",
    "        pcr_oi = features.get('pcr_oi', 0)\n",
    "        \n",
    "        print(f\"üîÑ PCR (Volume):      {pcr_volume:.3f}\")\n",
    "        print(f\"üîÑ PCR (OI):          {pcr_oi:.3f}\")\n",
    "        \n",
    "        if pcr_volume > 1.2:\n",
    "            pcr_signal = \"üìâ Bearish (High PCR)\"\n",
    "        elif pcr_volume < 0.8:\n",
    "            pcr_signal = \"üìà Bullish (Low PCR)\"\n",
    "        else:\n",
    "            pcr_signal = \"‚öñÔ∏è Neutral PCR\"\n",
    "        \n",
    "        print(f\"üéØ PCR Signal:        {pcr_signal}\")\n",
    "        \n",
    "        # Volume and OI indicators\n",
    "        total_volume = features.get('total_volume', 0)\n",
    "        total_oi = features.get('total_oi', 0)\n",
    "        \n",
    "        print(f\"üìä Total Volume:      {total_volume:,.0f}\")\n",
    "        print(f\"üìä Total OI:          {total_oi:,.0f}\")\n",
    "        \n",
    "        # ATM options activity\n",
    "        call_atm_ltp = features.get('call_atm_ltp', 0)\n",
    "        put_atm_ltp = features.get('put_atm_ltp', 0)\n",
    "        \n",
    "        print(f\"üí∞ ATM Call LTP:      ‚Çπ{call_atm_ltp:.2f}\")\n",
    "        print(f\"üí∞ ATM Put LTP:       ‚Çπ{put_atm_ltp:.2f}\")\n",
    "        \n",
    "        # Price momentum (if available)\n",
    "        price_change_pct = features.get('price_change_pct', 0)\n",
    "        if price_change_pct != 0:\n",
    "            print(f\"üìà Price Momentum:    {price_change_pct:+.2f}%\")\n",
    "        \n",
    "        # Model feature importance insights\n",
    "        if 'model_results' in globals():\n",
    "            top_features = model_results['feature_importance'].head(3)\n",
    "            print(f\"\\nüîç TOP DRIVING FACTORS\")\n",
    "            print(\"-\" * 22)\n",
    "            \n",
    "            for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "                feature_name = row['feature']\n",
    "                feature_value = features.get(feature_name, 0)\n",
    "                importance = row['importance']\n",
    "                \n",
    "                # Format feature name for display\n",
    "                display_name = feature_name.replace('_', ' ').title()\n",
    "                if len(display_name) > 20:\n",
    "                    display_name = display_name[:17] + \"...\"\n",
    "                \n",
    "                print(f\"{i}. {display_name:<20}: {feature_value:>8.2f}\")\n",
    "        \n",
    "        # Trading recommendation\n",
    "        print(f\"\\nüí° TRADING INSIGHTS\")\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        if abs(difference_pct) > 0.5:\n",
    "            if difference > 0:\n",
    "                print(\"üü¢ Model suggests upward movement\")\n",
    "                print(\"üí° Consider CALL options or long positions\")\n",
    "            else:\n",
    "                print(\"üî¥ Model suggests downward movement\") \n",
    "                print(\"üí° Consider PUT options or short positions\")\n",
    "        else:\n",
    "            print(\"üü° Model suggests sideways movement\")\n",
    "            print(\"üí° Consider range-bound strategies\")\n",
    "        \n",
    "        # Risk disclaimer\n",
    "        print(f\"\\n‚ö†Ô∏è  RISK DISCLAIMER\")\n",
    "        print(\"-\" * 15)\n",
    "        print(\"üìä This is a predictive model, not financial advice\")\n",
    "        print(\"üí∞ Always use proper risk management\")\n",
    "        print(\"üéØ Combine with other technical/fundamental analysis\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "        print(f\"‚ùå Prediction failed: {result['error']}\")\n",
    "        return None\n",
    "\n",
    "def run_continuous_predictions(cycles=3, interval_seconds=30):\n",
    "    \"\"\"\n",
    "    Run multiple prediction cycles with intervals\n",
    "    \n",
    "    Args:\n",
    "        cycles: Number of prediction cycles to run\n",
    "        interval_seconds: Seconds between predictions\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ STARTING CONTINUOUS PREDICTION MODE\")\n",
    "    print(f\"üìä Cycles: {cycles} | Interval: {interval_seconds}s\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for cycle in range(1, cycles + 1):\n",
    "        print(f\"\\nüîÑ CYCLE {cycle}/{cycles}\")\n",
    "        print(\"=\" * 20)\n",
    "        \n",
    "        result = run_live_prediction_cycle()\n",
    "        \n",
    "        if result:\n",
    "            results.append({\n",
    "                'cycle': cycle,\n",
    "                'timestamp': result['timestamp'],\n",
    "                'current_spot': result['current_spot'],\n",
    "                'predicted_spot': result['predicted_spot'],\n",
    "                'difference': result['difference'],\n",
    "                'difference_pct': result['difference_pct'],\n",
    "                'pcr_volume': result['features_used'].get('pcr_volume', 0),\n",
    "                'total_volume': result['features_used'].get('total_volume', 0)\n",
    "            })\n",
    "        \n",
    "        # Wait before next cycle (except for last cycle)\n",
    "        if cycle < cycles:\n",
    "            print(f\"\\n‚è≥ Waiting {interval_seconds} seconds for next cycle...\")\n",
    "            for remaining in range(interval_seconds, 0, -1):\n",
    "                print(f\"\\r‚è±Ô∏è  Next prediction in: {remaining:2d}s\", end=\"\", flush=True)\n",
    "                time.sleep(1)\n",
    "            print()  # New line after countdown\n",
    "    \n",
    "    # Summary of all cycles\n",
    "    if results:\n",
    "        print(f\"\\nüìä PREDICTION CYCLES SUMMARY\")\n",
    "        print(\"=\" * 35)\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        print(f\"‚úÖ Successful predictions: {len(results)}/{cycles}\")\n",
    "        print(f\"üí∞ Average predicted difference: ‚Çπ{results_df['difference'].mean():+.2f}\")\n",
    "        print(f\"üìä Average predicted change: {results_df['difference_pct'].mean():+.2f}%\")\n",
    "        print(f\"üîÑ Average PCR: {results_df['pcr_volume'].mean():.3f}\")\n",
    "        \n",
    "        # Show trend analysis\n",
    "        if len(results) > 1:\n",
    "            first_prediction = results_df.iloc[0]['predicted_spot']\n",
    "            last_prediction = results_df.iloc[-1]['predicted_spot']\n",
    "            trend = last_prediction - first_prediction\n",
    "            trend_pct = (trend / first_prediction) * 100\n",
    "            \n",
    "            print(f\"üìà Prediction trend: ‚Çπ{trend:+.2f} ({trend_pct:+.2f}%)\")\n",
    "            \n",
    "            if trend > 0:\n",
    "                print(\"üü¢ Overall bullish trend detected\")\n",
    "            elif trend < 0:\n",
    "                print(\"üî¥ Overall bearish trend detected\")\n",
    "            else:\n",
    "                print(\"üü° Sideways trend detected\")\n",
    "        \n",
    "        # Display results table\n",
    "        print(f\"\\nüìã DETAILED RESULTS\")\n",
    "        print(\"-\" * 20)\n",
    "        display_df = results_df[['cycle', 'timestamp', 'current_spot', 'predicted_spot', 'difference_pct', 'pcr_volume']].copy()\n",
    "        display_df.columns = ['Cycle', 'Time', 'Current ‚Çπ', 'Predicted ‚Çπ', 'Change %', 'PCR']\n",
    "        display_df['Time'] = display_df['Time'].dt.strftime('%H:%M:%S')\n",
    "        display_df['Current ‚Çπ'] = display_df['Current ‚Çπ'].round(2)\n",
    "        display_df['Predicted ‚Çπ'] = display_df['Predicted ‚Çπ'].round(2)\n",
    "        display_df['Change %'] = display_df['Change %'].round(2)\n",
    "        display_df['PCR'] = display_df['PCR'].round(3)\n",
    "        \n",
    "        display(display_df)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Interactive Interface\n",
    "print(f\"\\nüéõÔ∏è INTERACTIVE PREDICTION INTERFACE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    \n",
    "    # Create control widgets\n",
    "    single_prediction_button = widgets.Button(\n",
    "        description='üîÆ Single Prediction',\n",
    "        button_style='info',\n",
    "        layout={'width': '180px'}\n",
    "    )\n",
    "    \n",
    "    continuous_button = widgets.Button(\n",
    "        description='üîÑ Start Continuous',\n",
    "        button_style='success',\n",
    "        layout={'width': '180px'}\n",
    "    )\n",
    "    \n",
    "    cycles_slider = widgets.IntSlider(\n",
    "        value=3,\n",
    "        min=1,\n",
    "        max=10,\n",
    "        description='Cycles:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    interval_slider = widgets.IntSlider(\n",
    "        value=30,\n",
    "        min=10,\n",
    "        max=120,\n",
    "        step=10,\n",
    "        description='Interval (s):',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    output_widget = widgets.Output()\n",
    "    \n",
    "    def on_single_prediction_click(b):\n",
    "        with output_widget:\n",
    "            clear_output(wait=True)\n",
    "            run_live_prediction_cycle()\n",
    "    \n",
    "    def on_continuous_click(b):\n",
    "        with output_widget:\n",
    "            clear_output(wait=True)\n",
    "            run_continuous_predictions(\n",
    "                cycles=cycles_slider.value,\n",
    "                interval_seconds=interval_slider.value\n",
    "            )\n",
    "    \n",
    "    single_prediction_button.on_click(on_single_prediction_click)\n",
    "    continuous_button.on_click(on_continuous_click)\n",
    "    \n",
    "    # Create interface layout\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üöÄ Real-Time Prediction Controls</h3>\"),\n",
    "        widgets.HBox([single_prediction_button, continuous_button]),\n",
    "        widgets.HBox([cycles_slider, interval_slider]),\n",
    "        widgets.HTML(\"<p><b>Instructions:</b></p><ul><li>üîÆ <b>Single Prediction</b>: Run one prediction cycle</li><li>üîÑ <b>Continuous</b>: Run multiple cycles with intervals</li><li>‚öôÔ∏è Adjust cycles and interval as needed</li></ul>\")\n",
    "    ])\n",
    "    \n",
    "    interface = widgets.VBox([controls, output_widget])\n",
    "    display(interface)\n",
    "    \n",
    "    print(\"‚úÖ Interactive interface loaded successfully!\")\n",
    "    print(\"üí° Use the buttons above to start predictions\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"üìù Interactive interface requires ipywidgets\")\n",
    "    print(\"üí° Install with: pip install ipywidgets\")\n",
    "    print(\"\\nüîß MANUAL USAGE:\")\n",
    "    print(\"-\" * 15)\n",
    "    print(\"‚Ä¢ run_live_prediction_cycle() - Single prediction\")\n",
    "    print(\"‚Ä¢ run_continuous_predictions(cycles=3, interval_seconds=30) - Multiple predictions\")\n",
    "\n",
    "# Automatic single prediction on load (if model is available)\n",
    "if 'model_results' in globals() and kite is not None:\n",
    "    print(f\"\\nüöÄ RUNNING INITIAL PREDICTION...\")\n",
    "    initial_result = run_live_prediction_cycle()\n",
    "    \n",
    "    if initial_result:\n",
    "        print(f\"\\n‚úÖ Initial prediction completed successfully!\")\n",
    "        print(f\"üéØ You can now use the interface above for more predictions\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Initial prediction failed - please check your KiteConnect setup\")\n",
    "else:\n",
    "    if 'model_results' not in globals():\n",
    "        print(f\"\\n‚ö†Ô∏è XGBoost model not loaded. Please run the training cells first.\")\n",
    "    if kite is None:\n",
    "        print(f\"\\n‚ö†Ô∏è KiteConnect not initialized. Please check your API credentials.\")\n",
    "\n",
    "print(f\"\\nüéØ SYSTEM STATUS\")\n",
    "print(\"-\" * 15)\n",
    "print(f\"ü§ñ Model Ready: {'‚úÖ' if 'model_results' in globals() else '‚ùå'}\")\n",
    "print(f\"üì° KiteConnect: {'‚úÖ' if kite is not None else '‚ùå'}\")\n",
    "print(f\"üîÆ Prediction Functions: ‚úÖ\")\n",
    "print(f\"üí∞ Ready for Trading: {'‚úÖ' if 'model_results' in globals() and kite is not None else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí∞ LIVE BANK NIFTY SPOT PRICE FETCHER\n",
    "# Simple function to fetch current Bank Nifty spot price from KiteConnect\n",
    "\n",
    "def fetch_live_spot_price():\n",
    "    \"\"\"\n",
    "    Fetch current Bank Nifty spot price using KiteConnect\n",
    "    Returns: dict with spot price data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get Bank Nifty index instruments\n",
    "        indices = kite.instruments(\"INDICES\")\n",
    "        banknifty_index = [inst for inst in indices if inst['name'] == 'BANKNIFTY']\n",
    "        \n",
    "        if not banknifty_index:\n",
    "            return {\"error\": \"Bank Nifty index not found\"}\n",
    "        \n",
    "        # Get the instrument token for Bank Nifty\n",
    "        banknifty_token = banknifty_index[0]['instrument_token']\n",
    "        \n",
    "        # Fetch live quote\n",
    "        quote = kite.quote([banknifty_token])\n",
    "        spot_data = quote[str(banknifty_token)]\n",
    "        \n",
    "        # Extract relevant spot price information\n",
    "        result = {\n",
    "            'symbol': 'BANKNIFTY',\n",
    "            'last_price': spot_data['last_price'],\n",
    "            'open': spot_data['ohlc']['open'],\n",
    "            'high': spot_data['ohlc']['high'],\n",
    "            'low': spot_data['ohlc']['low'],\n",
    "            'close': spot_data['ohlc']['close'],\n",
    "            'change': spot_data['net_change'],\n",
    "            'change_percent': (spot_data['net_change'] / spot_data['ohlc']['close']) * 100 if spot_data['ohlc']['close'] > 0 else 0,\n",
    "            'volume': spot_data.get('volume', 0),\n",
    "            'timestamp': pd.Timestamp.now(),\n",
    "            'instrument_token': banknifty_token\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to fetch spot price: {str(e)}\"}\n",
    "\n",
    "def get_live_spot_and_options():\n",
    "    \"\"\"\n",
    "    Fetch both live spot price and options data together\n",
    "    Returns: dict with spot and options data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get live spot price\n",
    "        spot_result = fetch_live_spot_price()\n",
    "        \n",
    "        if 'error' in spot_result:\n",
    "            return spot_result\n",
    "        \n",
    "        spot_price = spot_result['last_price']\n",
    "        \n",
    "        # Get live options data around current spot\n",
    "        # Filter options for current expiry and nearby strikes\n",
    "        current_expiry_options = [opt for opt in banknifty_options \n",
    "                                if pd.to_datetime(opt['expiry']) == pd.to_datetime(banknifty_options[0]['expiry'])]\n",
    "        \n",
    "        # Filter options within ¬±500 points of spot price\n",
    "        nearby_options = [opt for opt in current_expiry_options \n",
    "                         if abs(opt['strike'] - spot_price) <= 500]\n",
    "        \n",
    "        if nearby_options:\n",
    "            # Get instrument tokens for nearby options\n",
    "            option_tokens = [opt['instrument_token'] for opt in nearby_options[:20]]  # Limit to 20 options\n",
    "            \n",
    "            # Fetch live quotes for options\n",
    "            option_quotes = kite.quote(option_tokens)\n",
    "            \n",
    "            # Process options data\n",
    "            calls_data = []\n",
    "            puts_data = []\n",
    "            \n",
    "            for opt in nearby_options[:20]:\n",
    "                token = str(opt['instrument_token'])\n",
    "                if token in option_quotes:\n",
    "                    quote_data = option_quotes[token]\n",
    "                    \n",
    "                    option_data = {\n",
    "                        'Strike Price': opt['strike'],\n",
    "                        'LTP': quote_data['last_price'],\n",
    "                        'Volume': quote_data.get('volume', 0),\n",
    "                        'OI': quote_data.get('oi', 0),\n",
    "                        'Bid': quote_data['depth']['buy'][0]['price'] if quote_data['depth']['buy'] else 0,\n",
    "                        'Ask': quote_data['depth']['sell'][0]['price'] if quote_data['depth']['sell'] else 0,\n",
    "                        'Change': quote_data['net_change'],\n",
    "                        'Symbol': opt['tradingsymbol']\n",
    "                    }\n",
    "                    \n",
    "                    if opt['instrument_type'] == 'CE':\n",
    "                        calls_data.append(option_data)\n",
    "                    elif opt['instrument_type'] == 'PE':\n",
    "                        puts_data.append(option_data)\n",
    "        \n",
    "        return {\n",
    "            'spot_data': spot_result,\n",
    "            'calls': pd.DataFrame(calls_data).sort_values('Strike Price') if calls_data else pd.DataFrame(),\n",
    "            'puts': pd.DataFrame(puts_data).sort_values('Strike Price') if puts_data else pd.DataFrame(),\n",
    "            'timestamp': pd.Timestamp.now()\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to fetch live data: {str(e)}\"}\n",
    "\n",
    "# Example usage functions\n",
    "def show_live_spot():\n",
    "    \"\"\"Display current Bank Nifty spot price\"\"\"\n",
    "    spot_data = fetch_live_spot_price()\n",
    "    \n",
    "    if 'error' in spot_data:\n",
    "        print(f\"‚ùå Error: {spot_data['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüí∞ LIVE BANK NIFTY SPOT PRICE\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"üè∑Ô∏è  Symbol: {spot_data['symbol']}\")\n",
    "    print(f\"üíµ Last Price: ‚Çπ{spot_data['last_price']:,.2f}\")\n",
    "    print(f\"üìà Change: ‚Çπ{spot_data['change']:,.2f} ({spot_data['change_percent']:+.2f}%)\")\n",
    "    print(f\"üìä OHLC: ‚Çπ{spot_data['open']:,.0f} | ‚Çπ{spot_data['high']:,.0f} | ‚Çπ{spot_data['low']:,.0f} | ‚Çπ{spot_data['close']:,.0f}\")\n",
    "    print(f\"üì¶ Volume: {spot_data['volume']:,}\")\n",
    "    print(f\"‚è∞ Time: {spot_data['timestamp'].strftime('%H:%M:%S')}\")\n",
    "\n",
    "def show_live_data_summary():\n",
    "    \"\"\"Display live spot price and top options\"\"\"\n",
    "    live_data = get_live_spot_and_options()\n",
    "    \n",
    "    if 'error' in live_data:\n",
    "        print(f\"‚ùå Error: {live_data['error']}\")\n",
    "        return\n",
    "    \n",
    "    # Show spot price\n",
    "    spot = live_data['spot_data']\n",
    "    print(f\"\\nüéØ LIVE MARKET DATA SUMMARY\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"üí∞ Bank Nifty: ‚Çπ{spot['last_price']:,.2f} ({spot['change_percent']:+.2f}%)\")\n",
    "    print(f\"‚è∞ Updated: {live_data['timestamp'].strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    # Show top 5 calls and puts\n",
    "    if not live_data['calls'].empty:\n",
    "        print(f\"\\nüìà TOP CALL OPTIONS:\")\n",
    "        print(\"-\" * 25)\n",
    "        calls_display = live_data['calls'].head(5)[['Strike Price', 'LTP', 'Volume', 'OI']]\n",
    "        for _, row in calls_display.iterrows():\n",
    "            print(f\"   {row['Strike Price']:,.0f}CE: ‚Çπ{row['LTP']:,.2f} | Vol: {row['Volume']:,} | OI: {row['OI']:,}\")\n",
    "    \n",
    "    if not live_data['puts'].empty:\n",
    "        print(f\"\\nüìâ TOP PUT OPTIONS:\")\n",
    "        print(\"-\" * 25)\n",
    "        puts_display = live_data['puts'].head(5)[['Strike Price', 'LTP', 'Volume', 'OI']]\n",
    "        for _, row in puts_display.iterrows():\n",
    "            print(f\"   {row['Strike Price']:,.0f}PE: ‚Çπ{row['LTP']:,.2f} | Vol: {row['Volume']:,} | OI: {row['OI']:,}\")\n",
    "\n",
    "# Make functions globally available\n",
    "globals()['fetch_live_spot_price'] = fetch_live_spot_price\n",
    "globals()['get_live_spot_and_options'] = get_live_spot_and_options\n",
    "globals()['show_live_spot'] = show_live_spot\n",
    "globals()['show_live_data_summary'] = show_live_data_summary\n",
    "\n",
    "print(\"\\nüí∞ LIVE SPOT PRICE FUNCTIONS LOADED!\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Available functions:\")\n",
    "print(\"‚Ä¢ fetch_live_spot_price() - Get raw spot price data\")\n",
    "print(\"‚Ä¢ get_live_spot_and_options() - Get spot + options data\")\n",
    "print(\"‚Ä¢ show_live_spot() - Display formatted spot price\")\n",
    "print(\"‚Ä¢ show_live_data_summary() - Display spot + top options\")\n",
    "\n",
    "print(\"\\nüí° Quick Test:\")\n",
    "print(\"Run: show_live_spot() or show_live_data_summary()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
